{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): ReLU(inplace=True)\n",
      "    (31): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (32): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (33): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (34): ReLU(inplace=True)\n",
      "    (35): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (36): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (37): ReLU(inplace=True)\n",
      "    (38): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (39): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (40): ReLU(inplace=True)\n",
      "    (41): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (42): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "ReLU(inplace=True)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "#from tensorboardX import SummaryWriter      \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "#from models import vgg_quant\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant\"\n",
    "model = VGG16_quant()\n",
    "print(model)\n",
    "print(model.features[26])\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    #adjust_list = [40, 80]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09ad5b14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.372 (0.372)\tData 0.204 (0.204)\tLoss 2.3849 (2.3849)\tPrec 15.625% (15.625%)\n",
      "Epoch: [0][100/391]\tTime 0.057 (0.060)\tData 0.002 (0.004)\tLoss 2.1634 (2.5237)\tPrec 18.750% (12.028%)\n",
      "Epoch: [0][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 2.3282 (2.3663)\tPrec 11.719% (14.179%)\n",
      "Epoch: [0][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 2.2102 (2.2900)\tPrec 14.062% (15.293%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 2.1143 (2.1143)\tPrec 21.875% (21.875%)\n",
      " * Prec 19.110% \n",
      "best acc: 19.110000\n",
      "Epoch: [1][0/391]\tTime 0.240 (0.240)\tData 0.196 (0.196)\tLoss 2.1457 (2.1457)\tPrec 17.969% (17.969%)\n",
      "Epoch: [1][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.004)\tLoss 2.2627 (2.0683)\tPrec 12.500% (19.732%)\n",
      "Epoch: [1][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 2.2487 (2.0731)\tPrec 8.594% (19.450%)\n",
      "Epoch: [1][300/391]\tTime 0.060 (0.057)\tData 0.002 (0.003)\tLoss 2.1032 (2.0684)\tPrec 21.094% (19.614%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.224 (0.224)\tLoss 1.9571 (1.9571)\tPrec 28.125% (28.125%)\n",
      " * Prec 23.310% \n",
      "best acc: 23.310000\n",
      "Epoch: [2][0/391]\tTime 0.266 (0.266)\tData 0.220 (0.220)\tLoss 1.9844 (1.9844)\tPrec 23.438% (23.438%)\n",
      "Epoch: [2][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 2.0033 (2.0292)\tPrec 20.312% (21.287%)\n",
      "Epoch: [2][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 1.9688 (2.0235)\tPrec 22.656% (21.514%)\n",
      "Epoch: [2][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 2.0543 (2.0183)\tPrec 25.781% (21.597%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.178 (0.178)\tLoss 1.8553 (1.8553)\tPrec 21.094% (21.094%)\n",
      " * Prec 26.500% \n",
      "best acc: 26.500000\n",
      "Epoch: [3][0/391]\tTime 0.250 (0.250)\tData 0.202 (0.202)\tLoss 1.9738 (1.9738)\tPrec 28.906% (28.906%)\n",
      "Epoch: [3][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 2.0232 (1.9765)\tPrec 22.656% (23.654%)\n",
      "Epoch: [3][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 2.0268 (1.9831)\tPrec 21.875% (23.115%)\n",
      "Epoch: [3][300/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 1.9956 (1.9751)\tPrec 26.562% (23.544%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 1.9968 (1.9968)\tPrec 26.562% (26.562%)\n",
      " * Prec 23.270% \n",
      "best acc: 26.500000\n",
      "Epoch: [4][0/391]\tTime 0.273 (0.273)\tData 0.221 (0.221)\tLoss 1.9867 (1.9867)\tPrec 25.781% (25.781%)\n",
      "Epoch: [4][100/391]\tTime 0.057 (0.060)\tData 0.002 (0.004)\tLoss 1.8362 (1.9460)\tPrec 25.781% (24.892%)\n",
      "Epoch: [4][200/391]\tTime 0.061 (0.058)\tData 0.002 (0.003)\tLoss 1.8736 (1.9401)\tPrec 22.656% (25.008%)\n",
      "Epoch: [4][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 2.0596 (1.9360)\tPrec 21.875% (24.878%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 1.9219 (1.9219)\tPrec 25.781% (25.781%)\n",
      " * Prec 25.310% \n",
      "best acc: 26.500000\n",
      "Epoch: [5][0/391]\tTime 0.238 (0.238)\tData 0.193 (0.193)\tLoss 1.8856 (1.8856)\tPrec 27.344% (27.344%)\n",
      "Epoch: [5][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 1.9020 (1.8968)\tPrec 28.906% (26.346%)\n",
      "Epoch: [5][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 1.8610 (1.9005)\tPrec 29.688% (26.356%)\n",
      "Epoch: [5][300/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 1.9812 (1.8940)\tPrec 22.656% (26.446%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.241 (0.241)\tLoss 1.8920 (1.8920)\tPrec 30.469% (30.469%)\n",
      " * Prec 27.770% \n",
      "best acc: 27.770000\n",
      "Epoch: [6][0/391]\tTime 0.228 (0.228)\tData 0.182 (0.182)\tLoss 1.8286 (1.8286)\tPrec 18.750% (18.750%)\n",
      "Epoch: [6][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 1.8733 (1.8641)\tPrec 25.781% (28.001%)\n",
      "Epoch: [6][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 1.9787 (1.8664)\tPrec 22.656% (27.799%)\n",
      "Epoch: [6][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.002)\tLoss 1.7708 (1.8602)\tPrec 30.469% (28.151%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 1.7610 (1.7610)\tPrec 33.594% (33.594%)\n",
      " * Prec 30.150% \n",
      "best acc: 30.150000\n",
      "Epoch: [7][0/391]\tTime 0.348 (0.348)\tData 0.303 (0.303)\tLoss 1.9022 (1.9022)\tPrec 27.344% (27.344%)\n",
      "Epoch: [7][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.005)\tLoss 1.8102 (1.8717)\tPrec 23.438% (27.522%)\n",
      "Epoch: [7][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.7445 (1.8686)\tPrec 34.375% (28.203%)\n",
      "Epoch: [7][300/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 1.8127 (1.8627)\tPrec 25.000% (28.382%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 1.7156 (1.7156)\tPrec 35.938% (35.938%)\n",
      " * Prec 31.650% \n",
      "best acc: 31.650000\n",
      "Epoch: [8][0/391]\tTime 0.239 (0.239)\tData 0.191 (0.191)\tLoss 1.8195 (1.8195)\tPrec 32.812% (32.812%)\n",
      "Epoch: [8][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.7555 (1.8365)\tPrec 33.594% (29.185%)\n",
      "Epoch: [8][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.9548 (1.8351)\tPrec 25.000% (29.268%)\n",
      "Epoch: [8][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.002)\tLoss 2.0751 (1.8354)\tPrec 23.438% (29.202%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 1.6826 (1.6826)\tPrec 34.375% (34.375%)\n",
      " * Prec 31.530% \n",
      "best acc: 31.650000\n",
      "Epoch: [9][0/391]\tTime 0.224 (0.224)\tData 0.184 (0.184)\tLoss 1.7108 (1.7108)\tPrec 35.156% (35.156%)\n",
      "Epoch: [9][100/391]\tTime 0.057 (0.058)\tData 0.002 (0.004)\tLoss 1.7963 (1.8219)\tPrec 32.812% (30.422%)\n",
      "Epoch: [9][200/391]\tTime 0.058 (0.058)\tData 0.003 (0.003)\tLoss 1.8673 (1.8424)\tPrec 28.125% (29.559%)\n",
      "Epoch: [9][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 1.7897 (1.8415)\tPrec 28.125% (29.612%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 1.7115 (1.7115)\tPrec 35.938% (35.938%)\n",
      " * Prec 28.960% \n",
      "best acc: 31.650000\n",
      "Epoch: [10][0/391]\tTime 0.237 (0.237)\tData 0.190 (0.190)\tLoss 1.8333 (1.8333)\tPrec 31.250% (31.250%)\n",
      "Epoch: [10][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.8103 (1.8181)\tPrec 27.344% (29.889%)\n",
      "Epoch: [10][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.7775 (1.8211)\tPrec 32.031% (29.516%)\n",
      "Epoch: [10][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 1.7913 (1.8288)\tPrec 30.469% (29.389%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.246 (0.246)\tLoss 1.8440 (1.8440)\tPrec 31.250% (31.250%)\n",
      " * Prec 30.450% \n",
      "best acc: 31.650000\n",
      "Epoch: [11][0/391]\tTime 0.277 (0.277)\tData 0.228 (0.228)\tLoss 1.9471 (1.9471)\tPrec 25.781% (25.781%)\n",
      "Epoch: [11][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 1.7531 (1.8064)\tPrec 36.719% (30.856%)\n",
      "Epoch: [11][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.7663 (1.8002)\tPrec 30.469% (30.931%)\n",
      "Epoch: [11][300/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 1.9044 (1.7960)\tPrec 29.688% (31.133%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 1.8035 (1.8035)\tPrec 35.156% (35.156%)\n",
      " * Prec 31.230% \n",
      "best acc: 31.650000\n",
      "Epoch: [12][0/391]\tTime 0.270 (0.270)\tData 0.227 (0.227)\tLoss 1.8196 (1.8196)\tPrec 32.031% (32.031%)\n",
      "Epoch: [12][100/391]\tTime 0.059 (0.060)\tData 0.002 (0.004)\tLoss 1.7239 (1.7690)\tPrec 31.250% (31.822%)\n",
      "Epoch: [12][200/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 1.8887 (1.7771)\tPrec 32.031% (31.569%)\n",
      "Epoch: [12][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.7064 (1.7795)\tPrec 31.250% (31.567%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 1.6627 (1.6627)\tPrec 36.719% (36.719%)\n",
      " * Prec 35.270% \n",
      "best acc: 35.270000\n",
      "Epoch: [13][0/391]\tTime 0.292 (0.292)\tData 0.243 (0.243)\tLoss 1.9060 (1.9060)\tPrec 28.125% (28.125%)\n",
      "Epoch: [13][100/391]\tTime 0.060 (0.060)\tData 0.002 (0.004)\tLoss 1.7266 (1.7856)\tPrec 35.156% (31.575%)\n",
      "Epoch: [13][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.6630 (1.7801)\tPrec 33.594% (31.514%)\n",
      "Epoch: [13][300/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 1.6147 (1.7726)\tPrec 31.250% (31.650%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 1.6388 (1.6388)\tPrec 35.938% (35.938%)\n",
      " * Prec 34.220% \n",
      "best acc: 35.270000\n",
      "Epoch: [14][0/391]\tTime 0.244 (0.244)\tData 0.200 (0.200)\tLoss 1.6207 (1.6207)\tPrec 39.062% (39.062%)\n",
      "Epoch: [14][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.7407 (1.7422)\tPrec 29.688% (33.029%)\n",
      "Epoch: [14][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.7334 (1.7539)\tPrec 28.906% (32.614%)\n",
      "Epoch: [14][300/391]\tTime 0.050 (0.058)\tData 0.002 (0.003)\tLoss 1.6592 (1.7476)\tPrec 33.594% (32.820%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 1.6231 (1.6231)\tPrec 36.719% (36.719%)\n",
      " * Prec 36.500% \n",
      "best acc: 36.500000\n",
      "Epoch: [15][0/391]\tTime 0.250 (0.250)\tData 0.210 (0.210)\tLoss 1.7106 (1.7106)\tPrec 33.594% (33.594%)\n",
      "Epoch: [15][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 1.6375 (1.7321)\tPrec 37.500% (33.687%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.7149 (1.7389)\tPrec 28.125% (33.283%)\n",
      "Epoch: [15][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 1.6826 (1.7377)\tPrec 45.312% (33.539%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 1.7006 (1.7006)\tPrec 32.031% (32.031%)\n",
      " * Prec 35.700% \n",
      "best acc: 36.500000\n",
      "Epoch: [16][0/391]\tTime 0.235 (0.235)\tData 0.193 (0.193)\tLoss 1.6405 (1.6405)\tPrec 35.156% (35.156%)\n",
      "Epoch: [16][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.004)\tLoss 1.7085 (1.7065)\tPrec 38.281% (35.241%)\n",
      "Epoch: [16][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.7677 (1.7135)\tPrec 35.938% (34.966%)\n",
      "Epoch: [16][300/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.6826 (1.7162)\tPrec 29.688% (34.780%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 1.6441 (1.6441)\tPrec 37.500% (37.500%)\n",
      " * Prec 36.020% \n",
      "best acc: 36.500000\n",
      "Epoch: [17][0/391]\tTime 0.300 (0.300)\tData 0.250 (0.250)\tLoss 1.7119 (1.7119)\tPrec 33.594% (33.594%)\n",
      "Epoch: [17][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.004)\tLoss 1.7906 (1.7142)\tPrec 32.031% (35.388%)\n",
      "Epoch: [17][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.7293 (1.7195)\tPrec 32.812% (34.616%)\n",
      "Epoch: [17][300/391]\tTime 0.053 (0.058)\tData 0.002 (0.003)\tLoss 1.6583 (1.7138)\tPrec 35.938% (34.829%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.251 (0.251)\tLoss 1.5865 (1.5865)\tPrec 35.156% (35.156%)\n",
      " * Prec 37.540% \n",
      "best acc: 37.540000\n",
      "Epoch: [18][0/391]\tTime 0.284 (0.284)\tData 0.237 (0.237)\tLoss 1.6164 (1.6164)\tPrec 41.406% (41.406%)\n",
      "Epoch: [18][100/391]\tTime 0.061 (0.059)\tData 0.002 (0.004)\tLoss 1.7543 (1.6824)\tPrec 29.688% (35.953%)\n",
      "Epoch: [18][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 1.8010 (1.6875)\tPrec 35.156% (35.382%)\n",
      "Epoch: [18][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.7151 (1.6995)\tPrec 31.250% (35.333%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 1.7143 (1.7143)\tPrec 34.375% (34.375%)\n",
      " * Prec 34.770% \n",
      "best acc: 37.540000\n",
      "Epoch: [19][0/391]\tTime 0.249 (0.249)\tData 0.211 (0.211)\tLoss 1.5596 (1.5596)\tPrec 39.844% (39.844%)\n",
      "Epoch: [19][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.7771 (1.6794)\tPrec 35.938% (35.651%)\n",
      "Epoch: [19][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 1.7274 (1.6786)\tPrec 32.031% (35.988%)\n",
      "Epoch: [19][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.003)\tLoss 1.7191 (1.6786)\tPrec 37.500% (36.098%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.256 (0.256)\tLoss 1.7207 (1.7207)\tPrec 32.031% (32.031%)\n",
      " * Prec 35.410% \n",
      "best acc: 37.540000\n",
      "Epoch: [20][0/391]\tTime 0.269 (0.269)\tData 0.227 (0.227)\tLoss 1.8287 (1.8287)\tPrec 34.375% (34.375%)\n",
      "Epoch: [20][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.5879 (1.7028)\tPrec 39.844% (35.767%)\n",
      "Epoch: [20][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.7869 (1.6915)\tPrec 30.469% (36.089%)\n",
      "Epoch: [20][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.6468 (1.6745)\tPrec 39.062% (36.867%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 1.5417 (1.5417)\tPrec 39.844% (39.844%)\n",
      " * Prec 38.640% \n",
      "best acc: 38.640000\n",
      "Epoch: [21][0/391]\tTime 0.245 (0.245)\tData 0.205 (0.205)\tLoss 1.6627 (1.6627)\tPrec 39.062% (39.062%)\n",
      "Epoch: [21][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.004)\tLoss 1.5961 (1.6687)\tPrec 42.969% (36.796%)\n",
      "Epoch: [21][200/391]\tTime 0.058 (0.058)\tData 0.003 (0.003)\tLoss 1.4986 (1.6588)\tPrec 40.625% (37.026%)\n",
      "Epoch: [21][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.4579 (1.6455)\tPrec 46.875% (37.697%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 1.6314 (1.6314)\tPrec 35.156% (35.156%)\n",
      " * Prec 37.880% \n",
      "best acc: 38.640000\n",
      "Epoch: [22][0/391]\tTime 0.287 (0.287)\tData 0.244 (0.244)\tLoss 1.6724 (1.6724)\tPrec 38.281% (38.281%)\n",
      "Epoch: [22][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.005)\tLoss 1.6811 (1.6575)\tPrec 35.156% (37.206%)\n",
      "Epoch: [22][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.6769 (1.6561)\tPrec 38.281% (37.193%)\n",
      "Epoch: [22][300/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 1.6677 (1.6402)\tPrec 41.406% (37.604%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 1.5491 (1.5491)\tPrec 36.719% (36.719%)\n",
      " * Prec 39.500% \n",
      "best acc: 39.500000\n",
      "Epoch: [23][0/391]\tTime 0.241 (0.241)\tData 0.199 (0.199)\tLoss 1.6858 (1.6858)\tPrec 33.594% (33.594%)\n",
      "Epoch: [23][100/391]\tTime 0.053 (0.059)\tData 0.002 (0.004)\tLoss 1.6326 (1.5972)\tPrec 32.031% (38.807%)\n",
      "Epoch: [23][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.7581 (1.6036)\tPrec 34.375% (38.930%)\n",
      "Epoch: [23][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.6352 (1.6117)\tPrec 37.500% (38.699%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.248 (0.248)\tLoss 1.5003 (1.5003)\tPrec 42.969% (42.969%)\n",
      " * Prec 41.620% \n",
      "best acc: 41.620000\n",
      "Epoch: [24][0/391]\tTime 0.221 (0.221)\tData 0.178 (0.178)\tLoss 1.5929 (1.5929)\tPrec 39.844% (39.844%)\n",
      "Epoch: [24][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.004)\tLoss 1.5636 (1.5895)\tPrec 42.969% (40.447%)\n",
      "Epoch: [24][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.5091 (1.5882)\tPrec 33.594% (40.201%)\n",
      "Epoch: [24][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 1.5193 (1.5821)\tPrec 45.312% (40.410%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.191 (0.191)\tLoss 1.5507 (1.5507)\tPrec 43.750% (43.750%)\n",
      " * Prec 39.850% \n",
      "best acc: 41.620000\n",
      "Epoch: [25][0/391]\tTime 0.278 (0.278)\tData 0.237 (0.237)\tLoss 1.4683 (1.4683)\tPrec 42.969% (42.969%)\n",
      "Epoch: [25][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.6054 (1.5913)\tPrec 37.500% (40.509%)\n",
      "Epoch: [25][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.4659 (1.5781)\tPrec 46.875% (40.792%)\n",
      "Epoch: [25][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.6157 (1.5757)\tPrec 39.844% (40.822%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 1.5112 (1.5112)\tPrec 42.188% (42.188%)\n",
      " * Prec 41.630% \n",
      "best acc: 41.630000\n",
      "Epoch: [26][0/391]\tTime 0.229 (0.229)\tData 0.185 (0.185)\tLoss 1.5907 (1.5907)\tPrec 38.281% (38.281%)\n",
      "Epoch: [26][100/391]\tTime 0.056 (0.059)\tData 0.003 (0.004)\tLoss 1.6044 (1.6057)\tPrec 39.062% (38.869%)\n",
      "Epoch: [26][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.5683 (1.5825)\tPrec 42.188% (39.852%)\n",
      "Epoch: [26][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.5452 (1.5795)\tPrec 35.938% (39.981%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 1.4853 (1.4853)\tPrec 42.969% (42.969%)\n",
      " * Prec 42.670% \n",
      "best acc: 42.670000\n",
      "Epoch: [27][0/391]\tTime 0.248 (0.248)\tData 0.199 (0.199)\tLoss 1.6610 (1.6610)\tPrec 37.500% (37.500%)\n",
      "Epoch: [27][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.5905 (1.5656)\tPrec 40.625% (41.166%)\n",
      "Epoch: [27][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.4006 (1.5512)\tPrec 49.219% (41.737%)\n",
      "Epoch: [27][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.5297 (1.5463)\tPrec 42.969% (41.749%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 1.5705 (1.5705)\tPrec 41.406% (41.406%)\n",
      " * Prec 43.840% \n",
      "best acc: 43.840000\n",
      "Epoch: [28][0/391]\tTime 0.289 (0.289)\tData 0.249 (0.249)\tLoss 1.5590 (1.5590)\tPrec 43.750% (43.750%)\n",
      "Epoch: [28][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.4955 (1.5549)\tPrec 37.500% (42.002%)\n",
      "Epoch: [28][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.4280 (1.5424)\tPrec 51.562% (41.869%)\n",
      "Epoch: [28][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.4002 (1.5374)\tPrec 45.312% (41.995%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 1.5149 (1.5149)\tPrec 45.312% (45.312%)\n",
      " * Prec 42.890% \n",
      "best acc: 43.840000\n",
      "Epoch: [29][0/391]\tTime 0.226 (0.226)\tData 0.185 (0.185)\tLoss 1.6083 (1.6083)\tPrec 34.375% (34.375%)\n",
      "Epoch: [29][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.4707 (1.5229)\tPrec 39.062% (41.870%)\n",
      "Epoch: [29][200/391]\tTime 0.057 (0.059)\tData 0.002 (0.003)\tLoss 1.4829 (1.5172)\tPrec 44.531% (42.417%)\n",
      "Epoch: [29][300/391]\tTime 0.059 (0.058)\tData 0.002 (0.002)\tLoss 1.5747 (1.5130)\tPrec 41.406% (42.927%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 1.4888 (1.4888)\tPrec 45.312% (45.312%)\n",
      " * Prec 43.220% \n",
      "best acc: 43.840000\n",
      "Epoch: [30][0/391]\tTime 0.245 (0.245)\tData 0.197 (0.197)\tLoss 1.5182 (1.5182)\tPrec 37.500% (37.500%)\n",
      "Epoch: [30][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.5530 (1.5231)\tPrec 37.500% (42.721%)\n",
      "Epoch: [30][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.4431 (1.5144)\tPrec 46.094% (43.109%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 1.4396 (1.5141)\tPrec 45.312% (42.938%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 1.5452 (1.5452)\tPrec 40.625% (40.625%)\n",
      " * Prec 42.400% \n",
      "best acc: 43.840000\n",
      "Epoch: [31][0/391]\tTime 0.282 (0.282)\tData 0.233 (0.233)\tLoss 1.5001 (1.5001)\tPrec 42.969% (42.969%)\n",
      "Epoch: [31][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.5881 (1.4869)\tPrec 35.156% (44.121%)\n",
      "Epoch: [31][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.4293 (1.4944)\tPrec 46.875% (43.699%)\n",
      "Epoch: [31][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.4329 (1.4936)\tPrec 44.531% (43.823%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 1.4283 (1.4283)\tPrec 51.562% (51.562%)\n",
      " * Prec 44.640% \n",
      "best acc: 44.640000\n",
      "Epoch: [32][0/391]\tTime 0.272 (0.272)\tData 0.220 (0.220)\tLoss 1.4462 (1.4462)\tPrec 41.406% (41.406%)\n",
      "Epoch: [32][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.7539 (1.4663)\tPrec 41.406% (44.933%)\n",
      "Epoch: [32][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.4155 (1.4693)\tPrec 50.781% (45.126%)\n",
      "Epoch: [32][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.5032 (1.4748)\tPrec 46.875% (45.058%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 1.5248 (1.5248)\tPrec 44.531% (44.531%)\n",
      " * Prec 45.080% \n",
      "best acc: 45.080000\n",
      "Epoch: [33][0/391]\tTime 0.269 (0.269)\tData 0.226 (0.226)\tLoss 1.5524 (1.5524)\tPrec 42.969% (42.969%)\n",
      "Epoch: [33][100/391]\tTime 0.060 (0.061)\tData 0.002 (0.004)\tLoss 1.5252 (1.4889)\tPrec 42.188% (44.206%)\n",
      "Epoch: [33][200/391]\tTime 0.059 (0.060)\tData 0.002 (0.003)\tLoss 1.5741 (1.4754)\tPrec 44.531% (44.640%)\n",
      "Epoch: [33][300/391]\tTime 0.057 (0.059)\tData 0.002 (0.003)\tLoss 1.4362 (1.4738)\tPrec 47.656% (44.716%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.194 (0.194)\tLoss 1.4387 (1.4387)\tPrec 48.438% (48.438%)\n",
      " * Prec 46.910% \n",
      "best acc: 46.910000\n",
      "Epoch: [34][0/391]\tTime 0.311 (0.311)\tData 0.263 (0.263)\tLoss 1.3837 (1.3837)\tPrec 52.344% (52.344%)\n",
      "Epoch: [34][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.5119 (1.4359)\tPrec 42.969% (46.194%)\n",
      "Epoch: [34][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3243 (1.4373)\tPrec 50.781% (46.292%)\n",
      "Epoch: [34][300/391]\tTime 0.054 (0.058)\tData 0.003 (0.003)\tLoss 1.5945 (1.4441)\tPrec 41.406% (46.089%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 1.4982 (1.4982)\tPrec 46.875% (46.875%)\n",
      " * Prec 46.770% \n",
      "best acc: 46.910000\n",
      "Epoch: [35][0/391]\tTime 0.261 (0.261)\tData 0.212 (0.212)\tLoss 1.4654 (1.4654)\tPrec 42.188% (42.188%)\n",
      "Epoch: [35][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.4436 (1.4680)\tPrec 46.094% (45.475%)\n",
      "Epoch: [35][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.4598 (1.4577)\tPrec 47.656% (45.744%)\n",
      "Epoch: [35][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.5392 (1.4517)\tPrec 41.406% (46.096%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 1.3382 (1.3382)\tPrec 46.875% (46.875%)\n",
      " * Prec 47.530% \n",
      "best acc: 47.530000\n",
      "Epoch: [36][0/391]\tTime 0.274 (0.274)\tData 0.233 (0.233)\tLoss 1.4450 (1.4450)\tPrec 47.656% (47.656%)\n",
      "Epoch: [36][100/391]\tTime 0.058 (0.061)\tData 0.002 (0.004)\tLoss 1.4664 (1.4290)\tPrec 48.438% (46.759%)\n",
      "Epoch: [36][200/391]\tTime 0.062 (0.060)\tData 0.002 (0.003)\tLoss 1.2738 (1.4293)\tPrec 56.250% (46.755%)\n",
      "Epoch: [36][300/391]\tTime 0.056 (0.059)\tData 0.002 (0.003)\tLoss 1.3347 (1.4311)\tPrec 47.656% (46.719%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.230 (0.230)\tLoss 1.3292 (1.3292)\tPrec 50.000% (50.000%)\n",
      " * Prec 48.430% \n",
      "best acc: 48.430000\n",
      "Epoch: [37][0/391]\tTime 0.254 (0.254)\tData 0.206 (0.206)\tLoss 1.3407 (1.3407)\tPrec 48.438% (48.438%)\n",
      "Epoch: [37][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.2622 (1.4195)\tPrec 54.688% (47.161%)\n",
      "Epoch: [37][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.5215 (1.4405)\tPrec 52.344% (46.626%)\n",
      "Epoch: [37][300/391]\tTime 0.062 (0.057)\tData 0.002 (0.003)\tLoss 1.5333 (1.4389)\tPrec 47.656% (46.758%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 1.4342 (1.4342)\tPrec 48.438% (48.438%)\n",
      " * Prec 47.840% \n",
      "best acc: 48.430000\n",
      "Epoch: [38][0/391]\tTime 0.266 (0.266)\tData 0.225 (0.225)\tLoss 1.4198 (1.4198)\tPrec 50.781% (50.781%)\n",
      "Epoch: [38][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.6297 (1.4317)\tPrec 42.188% (46.635%)\n",
      "Epoch: [38][200/391]\tTime 0.060 (0.058)\tData 0.001 (0.003)\tLoss 1.4818 (1.4297)\tPrec 42.188% (46.758%)\n",
      "Epoch: [38][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.3944 (1.4205)\tPrec 48.438% (47.410%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 1.4262 (1.4262)\tPrec 38.281% (38.281%)\n",
      " * Prec 46.650% \n",
      "best acc: 48.430000\n",
      "Epoch: [39][0/391]\tTime 0.247 (0.247)\tData 0.197 (0.197)\tLoss 1.4338 (1.4338)\tPrec 43.750% (43.750%)\n",
      "Epoch: [39][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.3158 (1.4220)\tPrec 52.344% (47.679%)\n",
      "Epoch: [39][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3943 (1.4124)\tPrec 46.875% (47.940%)\n",
      "Epoch: [39][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.4121 (1.4216)\tPrec 50.781% (47.552%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 1.3953 (1.3953)\tPrec 46.094% (46.094%)\n",
      " * Prec 48.900% \n",
      "best acc: 48.900000\n",
      "Epoch: [40][0/391]\tTime 0.227 (0.227)\tData 0.178 (0.178)\tLoss 1.5568 (1.5568)\tPrec 47.656% (47.656%)\n",
      "Epoch: [40][100/391]\tTime 0.058 (0.058)\tData 0.002 (0.004)\tLoss 1.3245 (1.3968)\tPrec 56.250% (49.219%)\n",
      "Epoch: [40][200/391]\tTime 0.051 (0.058)\tData 0.002 (0.003)\tLoss 1.4987 (1.4005)\tPrec 37.500% (48.601%)\n",
      "Epoch: [40][300/391]\tTime 0.060 (0.057)\tData 0.002 (0.002)\tLoss 1.4354 (1.4083)\tPrec 47.656% (47.994%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 1.3586 (1.3586)\tPrec 48.438% (48.438%)\n",
      " * Prec 48.710% \n",
      "best acc: 48.900000\n",
      "Epoch: [41][0/391]\tTime 0.261 (0.261)\tData 0.209 (0.209)\tLoss 1.2999 (1.2999)\tPrec 52.344% (52.344%)\n",
      "Epoch: [41][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.2775 (1.3812)\tPrec 50.000% (49.335%)\n",
      "Epoch: [41][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.3656 (1.3759)\tPrec 52.344% (49.584%)\n",
      "Epoch: [41][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.002)\tLoss 1.2546 (1.3743)\tPrec 51.562% (49.631%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.232 (0.232)\tLoss 1.3436 (1.3436)\tPrec 49.219% (49.219%)\n",
      " * Prec 48.460% \n",
      "best acc: 48.900000\n",
      "Epoch: [42][0/391]\tTime 0.253 (0.253)\tData 0.202 (0.202)\tLoss 1.4130 (1.4130)\tPrec 50.000% (50.000%)\n",
      "Epoch: [42][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.4498 (1.4174)\tPrec 46.875% (47.850%)\n",
      "Epoch: [42][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.2077 (1.3812)\tPrec 55.469% (49.312%)\n",
      "Epoch: [42][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.4302 (1.3748)\tPrec 48.438% (49.463%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 1.3473 (1.3473)\tPrec 53.125% (53.125%)\n",
      " * Prec 49.710% \n",
      "best acc: 49.710000\n",
      "Epoch: [43][0/391]\tTime 0.260 (0.260)\tData 0.211 (0.211)\tLoss 1.2889 (1.2889)\tPrec 52.344% (52.344%)\n",
      "Epoch: [43][100/391]\tTime 0.061 (0.060)\tData 0.002 (0.004)\tLoss 1.3235 (1.3580)\tPrec 49.219% (49.412%)\n",
      "Epoch: [43][200/391]\tTime 0.057 (0.059)\tData 0.002 (0.003)\tLoss 1.2850 (1.3603)\tPrec 50.781% (49.658%)\n",
      "Epoch: [43][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.3317 (1.3612)\tPrec 53.125% (49.881%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 1.3053 (1.3053)\tPrec 50.781% (50.781%)\n",
      " * Prec 49.900% \n",
      "best acc: 49.900000\n",
      "Epoch: [44][0/391]\tTime 0.278 (0.278)\tData 0.232 (0.232)\tLoss 1.2472 (1.2472)\tPrec 52.344% (52.344%)\n",
      "Epoch: [44][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.3869 (1.3483)\tPrec 50.000% (50.232%)\n",
      "Epoch: [44][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.2113 (1.3368)\tPrec 50.781% (50.408%)\n",
      "Epoch: [44][300/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.3456 (1.3336)\tPrec 47.656% (50.488%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 1.2813 (1.2813)\tPrec 50.000% (50.000%)\n",
      " * Prec 49.550% \n",
      "best acc: 49.900000\n",
      "Epoch: [45][0/391]\tTime 0.265 (0.265)\tData 0.220 (0.220)\tLoss 1.2613 (1.2613)\tPrec 56.250% (56.250%)\n",
      "Epoch: [45][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.4435 (1.3449)\tPrec 46.094% (50.286%)\n",
      "Epoch: [45][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.3944 (1.3428)\tPrec 42.188% (50.233%)\n",
      "Epoch: [45][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 1.6038 (1.3523)\tPrec 39.062% (49.862%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 1.2599 (1.2599)\tPrec 52.344% (52.344%)\n",
      " * Prec 50.710% \n",
      "best acc: 50.710000\n",
      "Epoch: [46][0/391]\tTime 0.260 (0.260)\tData 0.213 (0.213)\tLoss 1.2546 (1.2546)\tPrec 57.031% (57.031%)\n",
      "Epoch: [46][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.3332 (1.3117)\tPrec 47.656% (51.617%)\n",
      "Epoch: [46][200/391]\tTime 0.056 (0.059)\tData 0.002 (0.003)\tLoss 1.4339 (1.3255)\tPrec 45.312% (51.236%)\n",
      "Epoch: [46][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3428 (1.3257)\tPrec 49.219% (51.100%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 1.3043 (1.3043)\tPrec 57.031% (57.031%)\n",
      " * Prec 48.680% \n",
      "best acc: 50.710000\n",
      "Epoch: [47][0/391]\tTime 0.280 (0.280)\tData 0.232 (0.232)\tLoss 1.5344 (1.5344)\tPrec 48.438% (48.438%)\n",
      "Epoch: [47][100/391]\tTime 0.058 (0.059)\tData 0.001 (0.004)\tLoss 1.4471 (1.3600)\tPrec 45.312% (49.799%)\n",
      "Epoch: [47][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3338 (1.3554)\tPrec 52.344% (50.323%)\n",
      "Epoch: [47][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 1.3232 (1.3450)\tPrec 54.688% (50.714%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 1.2448 (1.2448)\tPrec 53.906% (53.906%)\n",
      " * Prec 52.250% \n",
      "best acc: 52.250000\n",
      "Epoch: [48][0/391]\tTime 0.258 (0.258)\tData 0.207 (0.207)\tLoss 1.1537 (1.1537)\tPrec 60.938% (60.938%)\n",
      "Epoch: [48][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 1.4293 (1.3181)\tPrec 45.312% (51.098%)\n",
      "Epoch: [48][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.6368 (1.3166)\tPrec 39.062% (51.182%)\n",
      "Epoch: [48][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 1.3850 (1.3179)\tPrec 45.312% (51.319%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 1.3275 (1.3275)\tPrec 51.562% (51.562%)\n",
      " * Prec 50.750% \n",
      "best acc: 52.250000\n",
      "Epoch: [49][0/391]\tTime 0.267 (0.267)\tData 0.223 (0.223)\tLoss 1.1529 (1.1529)\tPrec 58.594% (58.594%)\n",
      "Epoch: [49][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.1388 (1.2943)\tPrec 61.719% (52.529%)\n",
      "Epoch: [49][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3412 (1.2987)\tPrec 49.219% (52.348%)\n",
      "Epoch: [49][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 1.4454 (1.3096)\tPrec 44.531% (51.913%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.239 (0.239)\tLoss 1.1860 (1.1860)\tPrec 56.250% (56.250%)\n",
      " * Prec 52.810% \n",
      "best acc: 52.810000\n",
      "Epoch: [50][0/391]\tTime 0.256 (0.256)\tData 0.209 (0.209)\tLoss 1.2920 (1.2920)\tPrec 51.562% (51.562%)\n",
      "Epoch: [50][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.5035 (1.3205)\tPrec 38.281% (51.137%)\n",
      "Epoch: [50][200/391]\tTime 0.056 (0.058)\tData 0.003 (0.003)\tLoss 1.3272 (1.3058)\tPrec 57.031% (51.889%)\n",
      "Epoch: [50][300/391]\tTime 0.061 (0.057)\tData 0.002 (0.003)\tLoss 1.3393 (1.3018)\tPrec 45.312% (52.180%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.177 (0.177)\tLoss 1.1889 (1.1889)\tPrec 59.375% (59.375%)\n",
      " * Prec 54.550% \n",
      "best acc: 54.550000\n",
      "Epoch: [51][0/391]\tTime 0.242 (0.242)\tData 0.201 (0.201)\tLoss 1.2561 (1.2561)\tPrec 51.562% (51.562%)\n",
      "Epoch: [51][100/391]\tTime 0.057 (0.060)\tData 0.002 (0.004)\tLoss 1.2542 (1.3003)\tPrec 57.812% (52.692%)\n",
      "Epoch: [51][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.2945 (1.2970)\tPrec 50.781% (52.756%)\n",
      "Epoch: [51][300/391]\tTime 0.061 (0.058)\tData 0.002 (0.003)\tLoss 1.4757 (1.3014)\tPrec 45.312% (52.175%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 1.2637 (1.2637)\tPrec 55.469% (55.469%)\n",
      " * Prec 50.960% \n",
      "best acc: 54.550000\n",
      "Epoch: [52][0/391]\tTime 0.264 (0.264)\tData 0.215 (0.215)\tLoss 1.2105 (1.2105)\tPrec 52.344% (52.344%)\n",
      "Epoch: [52][100/391]\tTime 0.058 (0.060)\tData 0.002 (0.004)\tLoss 1.2037 (1.3065)\tPrec 53.125% (51.292%)\n",
      "Epoch: [52][200/391]\tTime 0.057 (0.059)\tData 0.002 (0.003)\tLoss 1.2470 (1.2890)\tPrec 53.906% (52.177%)\n",
      "Epoch: [52][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.3115 (1.2899)\tPrec 47.656% (52.557%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.245 (0.245)\tLoss 1.2182 (1.2182)\tPrec 53.906% (53.906%)\n",
      " * Prec 50.990% \n",
      "best acc: 54.550000\n",
      "Epoch: [53][0/391]\tTime 0.262 (0.262)\tData 0.212 (0.212)\tLoss 1.2836 (1.2836)\tPrec 50.000% (50.000%)\n",
      "Epoch: [53][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.1411 (1.2859)\tPrec 62.500% (53.048%)\n",
      "Epoch: [53][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 1.3861 (1.2901)\tPrec 52.344% (53.005%)\n",
      "Epoch: [53][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.3711 (1.2911)\tPrec 50.000% (52.806%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 1.1427 (1.1427)\tPrec 52.344% (52.344%)\n",
      " * Prec 54.470% \n",
      "best acc: 54.550000\n",
      "Epoch: [54][0/391]\tTime 0.326 (0.326)\tData 0.277 (0.277)\tLoss 1.3206 (1.3206)\tPrec 50.781% (50.781%)\n",
      "Epoch: [54][100/391]\tTime 0.056 (0.059)\tData 0.001 (0.004)\tLoss 1.4396 (1.2533)\tPrec 42.969% (53.790%)\n",
      "Epoch: [54][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 1.1292 (1.2597)\tPrec 53.125% (53.389%)\n",
      "Epoch: [54][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3245 (1.2626)\tPrec 52.344% (53.411%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 1.2861 (1.2861)\tPrec 48.438% (48.438%)\n",
      " * Prec 51.480% \n",
      "best acc: 54.550000\n",
      "Epoch: [55][0/391]\tTime 0.291 (0.291)\tData 0.244 (0.244)\tLoss 1.2264 (1.2264)\tPrec 52.344% (52.344%)\n",
      "Epoch: [55][100/391]\tTime 0.058 (0.060)\tData 0.002 (0.004)\tLoss 1.3290 (1.2703)\tPrec 53.125% (54.107%)\n",
      "Epoch: [55][200/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 1.2878 (1.2608)\tPrec 53.906% (54.027%)\n",
      "Epoch: [55][300/391]\tTime 0.057 (0.059)\tData 0.002 (0.003)\tLoss 1.3829 (1.2666)\tPrec 45.312% (53.686%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 1.1760 (1.1760)\tPrec 56.250% (56.250%)\n",
      " * Prec 54.430% \n",
      "best acc: 54.550000\n",
      "Epoch: [56][0/391]\tTime 0.262 (0.262)\tData 0.211 (0.211)\tLoss 1.2768 (1.2768)\tPrec 52.344% (52.344%)\n",
      "Epoch: [56][100/391]\tTime 0.059 (0.060)\tData 0.002 (0.004)\tLoss 1.1680 (1.2730)\tPrec 57.812% (53.117%)\n",
      "Epoch: [56][200/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 1.2561 (1.2569)\tPrec 56.250% (53.813%)\n",
      "Epoch: [56][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.2591 (1.2520)\tPrec 53.906% (54.028%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.240 (0.240)\tLoss 1.2366 (1.2366)\tPrec 58.594% (58.594%)\n",
      " * Prec 55.320% \n",
      "best acc: 55.320000\n",
      "Epoch: [57][0/391]\tTime 0.267 (0.267)\tData 0.223 (0.223)\tLoss 1.0977 (1.0977)\tPrec 58.594% (58.594%)\n",
      "Epoch: [57][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 1.1133 (1.2440)\tPrec 63.281% (55.090%)\n",
      "Epoch: [57][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3122 (1.2592)\tPrec 53.125% (54.244%)\n",
      "Epoch: [57][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 1.1724 (1.2608)\tPrec 57.812% (53.867%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 1.1224 (1.1224)\tPrec 60.156% (60.156%)\n",
      " * Prec 54.290% \n",
      "best acc: 55.320000\n",
      "Epoch: [58][0/391]\tTime 0.267 (0.267)\tData 0.217 (0.217)\tLoss 1.2074 (1.2074)\tPrec 57.031% (57.031%)\n",
      "Epoch: [58][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.004)\tLoss 1.2720 (1.2423)\tPrec 54.688% (54.649%)\n",
      "Epoch: [58][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.2738 (1.2479)\tPrec 53.125% (54.528%)\n",
      "Epoch: [58][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 1.1943 (1.2356)\tPrec 57.031% (54.996%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 1.1800 (1.1800)\tPrec 53.906% (53.906%)\n",
      " * Prec 54.600% \n",
      "best acc: 55.320000\n",
      "Epoch: [59][0/391]\tTime 0.250 (0.250)\tData 0.200 (0.200)\tLoss 1.1970 (1.1970)\tPrec 52.344% (52.344%)\n",
      "Epoch: [59][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.1819 (1.2308)\tPrec 59.375% (55.244%)\n",
      "Epoch: [59][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.0461 (1.2288)\tPrec 64.062% (55.158%)\n",
      "Epoch: [59][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.002)\tLoss 1.4446 (1.2216)\tPrec 53.906% (55.329%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 1.3436 (1.3436)\tPrec 50.781% (50.781%)\n",
      " * Prec 53.540% \n",
      "best acc: 55.320000\n",
      "Epoch: [60][0/391]\tTime 0.254 (0.254)\tData 0.214 (0.214)\tLoss 1.2290 (1.2290)\tPrec 55.469% (55.469%)\n",
      "Epoch: [60][100/391]\tTime 0.060 (0.060)\tData 0.002 (0.004)\tLoss 1.2922 (1.2334)\tPrec 55.469% (55.213%)\n",
      "Epoch: [60][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.0742 (1.2325)\tPrec 61.719% (55.092%)\n",
      "Epoch: [60][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.2053 (1.2322)\tPrec 57.812% (55.033%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 1.0915 (1.0915)\tPrec 59.375% (59.375%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 57.120% \n",
      "best acc: 57.120000\n",
      "Epoch: [61][0/391]\tTime 0.297 (0.297)\tData 0.252 (0.252)\tLoss 1.1352 (1.1352)\tPrec 60.938% (60.938%)\n",
      "Epoch: [61][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.2572 (1.2067)\tPrec 50.000% (55.902%)\n",
      "Epoch: [61][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.1994 (1.2123)\tPrec 57.812% (55.838%)\n",
      "Epoch: [61][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 1.0444 (1.2061)\tPrec 65.625% (56.172%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.234 (0.234)\tLoss 1.2448 (1.2448)\tPrec 52.344% (52.344%)\n",
      " * Prec 56.370% \n",
      "best acc: 57.120000\n",
      "Epoch: [62][0/391]\tTime 0.272 (0.272)\tData 0.225 (0.225)\tLoss 1.2905 (1.2905)\tPrec 53.125% (53.125%)\n",
      "Epoch: [62][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.3815 (1.2017)\tPrec 52.344% (56.026%)\n",
      "Epoch: [62][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.1956 (1.1925)\tPrec 52.344% (56.405%)\n",
      "Epoch: [62][300/391]\tTime 0.063 (0.058)\tData 0.002 (0.003)\tLoss 1.3129 (1.1897)\tPrec 52.344% (56.471%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 1.0823 (1.0823)\tPrec 57.031% (57.031%)\n",
      " * Prec 56.120% \n",
      "best acc: 57.120000\n",
      "Epoch: [63][0/391]\tTime 0.240 (0.240)\tData 0.193 (0.193)\tLoss 1.1814 (1.1814)\tPrec 59.375% (59.375%)\n",
      "Epoch: [63][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.1527 (1.1746)\tPrec 59.375% (57.596%)\n",
      "Epoch: [63][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.2433 (1.1893)\tPrec 54.688% (57.074%)\n",
      "Epoch: [63][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 1.1593 (1.1875)\tPrec 57.031% (57.049%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 1.1675 (1.1675)\tPrec 57.031% (57.031%)\n",
      " * Prec 55.470% \n",
      "best acc: 57.120000\n",
      "Epoch: [64][0/391]\tTime 0.255 (0.255)\tData 0.200 (0.200)\tLoss 1.1727 (1.1727)\tPrec 54.688% (54.688%)\n",
      "Epoch: [64][100/391]\tTime 0.059 (0.061)\tData 0.002 (0.004)\tLoss 1.2363 (1.2215)\tPrec 56.250% (55.840%)\n",
      "Epoch: [64][200/391]\tTime 0.058 (0.060)\tData 0.002 (0.003)\tLoss 1.4587 (1.2132)\tPrec 48.438% (55.710%)\n",
      "Epoch: [64][300/391]\tTime 0.062 (0.059)\tData 0.002 (0.002)\tLoss 1.2372 (1.2161)\tPrec 53.125% (55.749%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 1.1505 (1.1505)\tPrec 53.906% (53.906%)\n",
      " * Prec 56.250% \n",
      "best acc: 57.120000\n",
      "Epoch: [65][0/391]\tTime 0.273 (0.273)\tData 0.226 (0.226)\tLoss 1.2540 (1.2540)\tPrec 55.469% (55.469%)\n",
      "Epoch: [65][100/391]\tTime 0.064 (0.060)\tData 0.002 (0.004)\tLoss 1.1497 (1.2100)\tPrec 54.688% (56.002%)\n",
      "Epoch: [65][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.0574 (1.1971)\tPrec 58.594% (56.374%)\n",
      "Epoch: [65][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9696 (1.1852)\tPrec 69.531% (57.039%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.246 (0.246)\tLoss 1.2201 (1.2201)\tPrec 53.125% (53.125%)\n",
      " * Prec 54.810% \n",
      "best acc: 57.120000\n",
      "Epoch: [66][0/391]\tTime 0.267 (0.267)\tData 0.221 (0.221)\tLoss 1.3475 (1.3475)\tPrec 51.562% (51.562%)\n",
      "Epoch: [66][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.2222 (1.2022)\tPrec 53.906% (56.018%)\n",
      "Epoch: [66][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.2869 (1.2064)\tPrec 54.688% (56.308%)\n",
      "Epoch: [66][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3760 (1.2132)\tPrec 47.656% (55.985%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.257 (0.257)\tLoss 1.1741 (1.1741)\tPrec 57.031% (57.031%)\n",
      " * Prec 56.390% \n",
      "best acc: 57.120000\n",
      "Epoch: [67][0/391]\tTime 0.266 (0.266)\tData 0.217 (0.217)\tLoss 1.2542 (1.2542)\tPrec 56.250% (56.250%)\n",
      "Epoch: [67][100/391]\tTime 0.057 (0.060)\tData 0.002 (0.004)\tLoss 1.2587 (1.1887)\tPrec 54.688% (57.627%)\n",
      "Epoch: [67][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.0332 (1.1870)\tPrec 58.594% (57.606%)\n",
      "Epoch: [67][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.1819 (1.1876)\tPrec 60.938% (57.566%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.243 (0.243)\tLoss 1.1875 (1.1875)\tPrec 60.156% (60.156%)\n",
      " * Prec 56.920% \n",
      "best acc: 57.120000\n",
      "Epoch: [68][0/391]\tTime 0.248 (0.248)\tData 0.201 (0.201)\tLoss 1.1819 (1.1819)\tPrec 54.688% (54.688%)\n",
      "Epoch: [68][100/391]\tTime 0.048 (0.059)\tData 0.002 (0.004)\tLoss 1.1669 (1.1854)\tPrec 57.812% (56.815%)\n",
      "Epoch: [68][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.0077 (1.1882)\tPrec 63.281% (56.670%)\n",
      "Epoch: [68][300/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.1934 (1.1912)\tPrec 56.250% (56.722%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 1.1857 (1.1857)\tPrec 53.906% (53.906%)\n",
      " * Prec 57.290% \n",
      "best acc: 57.290000\n",
      "Epoch: [69][0/391]\tTime 0.279 (0.279)\tData 0.233 (0.233)\tLoss 1.2660 (1.2660)\tPrec 53.906% (53.906%)\n",
      "Epoch: [69][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.004)\tLoss 1.1545 (1.1868)\tPrec 57.031% (56.923%)\n",
      "Epoch: [69][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.0847 (1.1747)\tPrec 67.188% (57.381%)\n",
      "Epoch: [69][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.1747 (1.1735)\tPrec 57.031% (57.361%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 1.1701 (1.1701)\tPrec 60.938% (60.938%)\n",
      " * Prec 57.230% \n",
      "best acc: 57.290000\n",
      "Epoch: [70][0/391]\tTime 0.231 (0.231)\tData 0.182 (0.182)\tLoss 1.0772 (1.0772)\tPrec 57.812% (57.812%)\n",
      "Epoch: [70][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.2210 (1.1565)\tPrec 56.250% (58.246%)\n",
      "Epoch: [70][200/391]\tTime 0.058 (0.058)\tData 0.001 (0.003)\tLoss 1.1222 (1.1471)\tPrec 56.250% (58.516%)\n",
      "Epoch: [70][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 1.3873 (1.1631)\tPrec 47.656% (57.693%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 1.0656 (1.0656)\tPrec 61.719% (61.719%)\n",
      " * Prec 57.500% \n",
      "best acc: 57.500000\n",
      "Epoch: [71][0/391]\tTime 0.278 (0.278)\tData 0.231 (0.231)\tLoss 1.2993 (1.2993)\tPrec 48.438% (48.438%)\n",
      "Epoch: [71][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.9845 (1.1467)\tPrec 64.844% (58.045%)\n",
      "Epoch: [71][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.1426 (1.1501)\tPrec 57.812% (58.256%)\n",
      "Epoch: [71][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 1.1632 (1.1487)\tPrec 58.594% (58.622%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 1.0877 (1.0877)\tPrec 58.594% (58.594%)\n",
      " * Prec 59.190% \n",
      "best acc: 59.190000\n",
      "Epoch: [72][0/391]\tTime 0.260 (0.260)\tData 0.212 (0.212)\tLoss 1.0686 (1.0686)\tPrec 63.281% (63.281%)\n",
      "Epoch: [72][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.004)\tLoss 1.1795 (1.1542)\tPrec 60.156% (58.772%)\n",
      "Epoch: [72][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.2911 (1.1486)\tPrec 53.125% (58.644%)\n",
      "Epoch: [72][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.2211 (1.1441)\tPrec 53.906% (58.827%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 1.1602 (1.1602)\tPrec 55.469% (55.469%)\n",
      " * Prec 57.730% \n",
      "best acc: 59.190000\n",
      "Epoch: [73][0/391]\tTime 0.292 (0.292)\tData 0.245 (0.245)\tLoss 0.9325 (0.9325)\tPrec 71.094% (71.094%)\n",
      "Epoch: [73][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.0617 (1.1266)\tPrec 63.281% (58.957%)\n",
      "Epoch: [73][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0878 (1.1269)\tPrec 53.906% (59.107%)\n",
      "Epoch: [73][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 1.0904 (1.1452)\tPrec 60.156% (58.399%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 1.1497 (1.1497)\tPrec 55.469% (55.469%)\n",
      " * Prec 57.250% \n",
      "best acc: 59.190000\n",
      "Epoch: [74][0/391]\tTime 0.311 (0.311)\tData 0.265 (0.265)\tLoss 1.1346 (1.1346)\tPrec 60.156% (60.156%)\n",
      "Epoch: [74][100/391]\tTime 0.061 (0.060)\tData 0.001 (0.005)\tLoss 1.2939 (1.1387)\tPrec 51.562% (58.826%)\n",
      "Epoch: [74][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.9766 (1.1374)\tPrec 66.406% (58.706%)\n",
      "Epoch: [74][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.2488 (1.1476)\tPrec 53.906% (58.461%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 1.1416 (1.1416)\tPrec 57.812% (57.812%)\n",
      " * Prec 57.410% \n",
      "best acc: 59.190000\n",
      "Epoch: [75][0/391]\tTime 0.269 (0.269)\tData 0.224 (0.224)\tLoss 1.1559 (1.1559)\tPrec 57.031% (57.031%)\n",
      "Epoch: [75][100/391]\tTime 0.059 (0.059)\tData 0.001 (0.004)\tLoss 1.1070 (1.1380)\tPrec 57.812% (58.911%)\n",
      "Epoch: [75][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.2804 (1.1375)\tPrec 52.344% (58.947%)\n",
      "Epoch: [75][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0955 (1.1370)\tPrec 64.062% (59.108%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 1.0620 (1.0620)\tPrec 59.375% (59.375%)\n",
      " * Prec 59.230% \n",
      "best acc: 59.230000\n",
      "Epoch: [76][0/391]\tTime 0.266 (0.266)\tData 0.220 (0.220)\tLoss 0.9989 (0.9989)\tPrec 71.875% (71.875%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [76][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.2448 (1.1256)\tPrec 53.906% (59.916%)\n",
      "Epoch: [76][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.1218 (1.1309)\tPrec 57.031% (59.573%)\n",
      "Epoch: [76][300/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.1927 (1.1290)\tPrec 58.594% (59.430%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 1.0547 (1.0547)\tPrec 64.844% (64.844%)\n",
      " * Prec 60.440% \n",
      "best acc: 60.440000\n",
      "Epoch: [77][0/391]\tTime 0.274 (0.274)\tData 0.226 (0.226)\tLoss 1.1108 (1.1108)\tPrec 54.688% (54.688%)\n",
      "Epoch: [77][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.1241 (1.1097)\tPrec 58.594% (59.916%)\n",
      "Epoch: [77][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.1569 (1.1152)\tPrec 58.594% (59.748%)\n",
      "Epoch: [77][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.1912 (1.1178)\tPrec 56.250% (59.681%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 1.1210 (1.1210)\tPrec 59.375% (59.375%)\n",
      " * Prec 59.780% \n",
      "best acc: 60.440000\n",
      "Epoch: [78][0/391]\tTime 0.280 (0.280)\tData 0.235 (0.235)\tLoss 1.0475 (1.0475)\tPrec 64.844% (64.844%)\n",
      "Epoch: [78][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.0591 (1.1013)\tPrec 58.594% (60.125%)\n",
      "Epoch: [78][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.3097 (1.0978)\tPrec 54.688% (60.436%)\n",
      "Epoch: [78][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0593 (1.1040)\tPrec 64.062% (60.182%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 1.0890 (1.0890)\tPrec 58.594% (58.594%)\n",
      " * Prec 59.960% \n",
      "best acc: 60.440000\n",
      "Epoch: [79][0/391]\tTime 0.327 (0.327)\tData 0.280 (0.280)\tLoss 0.9197 (0.9197)\tPrec 65.625% (65.625%)\n",
      "Epoch: [79][100/391]\tTime 0.059 (0.060)\tData 0.002 (0.005)\tLoss 1.1291 (1.1135)\tPrec 58.594% (59.568%)\n",
      "Epoch: [79][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0615 (1.0883)\tPrec 60.938% (60.681%)\n",
      "Epoch: [79][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.0496 (1.0937)\tPrec 63.281% (60.395%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 1.0430 (1.0430)\tPrec 61.719% (61.719%)\n",
      " * Prec 61.130% \n",
      "best acc: 61.130000\n",
      "Epoch: [80][0/391]\tTime 0.264 (0.264)\tData 0.212 (0.212)\tLoss 1.2726 (1.2726)\tPrec 52.344% (52.344%)\n",
      "Epoch: [80][100/391]\tTime 0.060 (0.059)\tData 0.002 (0.004)\tLoss 1.0880 (1.1600)\tPrec 60.156% (58.230%)\n",
      "Epoch: [80][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.1389 (1.1399)\tPrec 60.938% (59.045%)\n",
      "Epoch: [80][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.1569 (1.1236)\tPrec 60.938% (59.487%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.9530 (0.9530)\tPrec 62.500% (62.500%)\n",
      " * Prec 61.900% \n",
      "best acc: 61.900000\n",
      "Epoch: [81][0/391]\tTime 0.257 (0.257)\tData 0.212 (0.212)\tLoss 1.1510 (1.1510)\tPrec 58.594% (58.594%)\n",
      "Epoch: [81][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.1723 (1.0746)\tPrec 61.719% (60.845%)\n",
      "Epoch: [81][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.0745 (1.0872)\tPrec 57.812% (60.615%)\n",
      "Epoch: [81][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.9478 (1.0804)\tPrec 68.750% (60.966%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 1.0288 (1.0288)\tPrec 62.500% (62.500%)\n",
      " * Prec 60.610% \n",
      "best acc: 61.900000\n",
      "Epoch: [82][0/391]\tTime 0.330 (0.330)\tData 0.283 (0.283)\tLoss 1.0305 (1.0305)\tPrec 62.500% (62.500%)\n",
      "Epoch: [82][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.005)\tLoss 1.1552 (1.1163)\tPrec 60.156% (59.708%)\n",
      "Epoch: [82][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.1466 (1.1040)\tPrec 57.812% (60.347%)\n",
      "Epoch: [82][300/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 1.0205 (1.1030)\tPrec 61.719% (60.473%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 1.0186 (1.0186)\tPrec 63.281% (63.281%)\n",
      " * Prec 61.110% \n",
      "best acc: 61.900000\n",
      "Epoch: [83][0/391]\tTime 0.266 (0.266)\tData 0.224 (0.224)\tLoss 1.1069 (1.1069)\tPrec 58.594% (58.594%)\n",
      "Epoch: [83][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.8937 (1.1079)\tPrec 69.531% (59.978%)\n",
      "Epoch: [83][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.0356 (1.1038)\tPrec 66.406% (60.323%)\n",
      "Epoch: [83][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.1122 (1.0878)\tPrec 57.031% (60.961%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.238 (0.238)\tLoss 1.1067 (1.1067)\tPrec 59.375% (59.375%)\n",
      " * Prec 60.450% \n",
      "best acc: 61.900000\n",
      "Epoch: [84][0/391]\tTime 0.279 (0.279)\tData 0.231 (0.231)\tLoss 1.0261 (1.0261)\tPrec 61.719% (61.719%)\n",
      "Epoch: [84][100/391]\tTime 0.060 (0.059)\tData 0.002 (0.004)\tLoss 0.9794 (1.0737)\tPrec 63.281% (61.665%)\n",
      "Epoch: [84][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.1544 (1.0821)\tPrec 57.812% (61.245%)\n",
      "Epoch: [84][300/391]\tTime 0.061 (0.058)\tData 0.002 (0.003)\tLoss 1.1391 (1.0825)\tPrec 57.812% (61.293%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.191 (0.191)\tLoss 0.9850 (0.9850)\tPrec 63.281% (63.281%)\n",
      " * Prec 61.540% \n",
      "best acc: 61.900000\n",
      "Epoch: [85][0/391]\tTime 0.274 (0.274)\tData 0.224 (0.224)\tLoss 1.0515 (1.0515)\tPrec 62.500% (62.500%)\n",
      "Epoch: [85][100/391]\tTime 0.061 (0.059)\tData 0.002 (0.004)\tLoss 0.9903 (1.1061)\tPrec 68.750% (60.280%)\n",
      "Epoch: [85][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.2486 (1.1085)\tPrec 60.938% (60.183%)\n",
      "Epoch: [85][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.0904 (1.1055)\tPrec 63.281% (60.270%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.341 (0.341)\tLoss 1.0453 (1.0453)\tPrec 60.938% (60.938%)\n",
      " * Prec 62.770% \n",
      "best acc: 62.770000\n",
      "Epoch: [86][0/391]\tTime 0.237 (0.237)\tData 0.197 (0.197)\tLoss 0.9206 (0.9206)\tPrec 66.406% (66.406%)\n",
      "Epoch: [86][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.9048 (1.0678)\tPrec 72.656% (61.928%)\n",
      "Epoch: [86][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.1252 (1.0801)\tPrec 64.062% (61.590%)\n",
      "Epoch: [86][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.0040 (1.0782)\tPrec 61.719% (61.480%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 1.0168 (1.0168)\tPrec 63.281% (63.281%)\n",
      " * Prec 61.290% \n",
      "best acc: 62.770000\n",
      "Epoch: [87][0/391]\tTime 0.301 (0.301)\tData 0.257 (0.257)\tLoss 1.1399 (1.1399)\tPrec 59.375% (59.375%)\n",
      "Epoch: [87][100/391]\tTime 0.060 (0.059)\tData 0.002 (0.005)\tLoss 1.0663 (1.0777)\tPrec 60.156% (61.386%)\n",
      "Epoch: [87][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.1563 (1.0745)\tPrec 56.250% (61.590%)\n",
      "Epoch: [87][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0117 (1.0702)\tPrec 60.156% (61.716%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.9534 (0.9534)\tPrec 64.062% (64.062%)\n",
      " * Prec 62.760% \n",
      "best acc: 62.770000\n",
      "Epoch: [88][0/391]\tTime 0.259 (0.259)\tData 0.215 (0.215)\tLoss 1.0876 (1.0876)\tPrec 62.500% (62.500%)\n",
      "Epoch: [88][100/391]\tTime 0.057 (0.060)\tData 0.002 (0.004)\tLoss 0.9641 (1.0368)\tPrec 65.625% (62.748%)\n",
      "Epoch: [88][200/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 1.2244 (1.0474)\tPrec 57.812% (62.535%)\n",
      "Epoch: [88][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9541 (1.0577)\tPrec 66.406% (62.209%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 1.0914 (1.0914)\tPrec 58.594% (58.594%)\n",
      " * Prec 60.180% \n",
      "best acc: 62.770000\n",
      "Epoch: [89][0/391]\tTime 0.272 (0.272)\tData 0.225 (0.225)\tLoss 0.9050 (0.9050)\tPrec 67.969% (67.969%)\n",
      "Epoch: [89][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.9810 (1.0874)\tPrec 65.625% (61.092%)\n",
      "Epoch: [89][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 1.0084 (1.0755)\tPrec 66.406% (61.540%)\n",
      "Epoch: [89][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 0.9770 (1.0752)\tPrec 68.750% (61.387%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.175 (0.175)\tLoss 0.9500 (0.9500)\tPrec 66.406% (66.406%)\n",
      " * Prec 62.320% \n",
      "best acc: 62.770000\n",
      "Epoch: [90][0/391]\tTime 0.247 (0.247)\tData 0.199 (0.199)\tLoss 1.0178 (1.0178)\tPrec 64.062% (64.062%)\n",
      "Epoch: [90][100/391]\tTime 0.057 (0.059)\tData 0.001 (0.004)\tLoss 1.0649 (1.0395)\tPrec 62.500% (62.384%)\n",
      "Epoch: [90][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 0.9854 (1.0292)\tPrec 64.844% (62.951%)\n",
      "Epoch: [90][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.003)\tLoss 0.9785 (1.0286)\tPrec 70.312% (62.853%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 0.8968 (0.8968)\tPrec 67.188% (67.188%)\n",
      " * Prec 64.420% \n",
      "best acc: 64.420000\n",
      "Epoch: [91][0/391]\tTime 0.273 (0.273)\tData 0.231 (0.231)\tLoss 1.0075 (1.0075)\tPrec 64.062% (64.062%)\n",
      "Epoch: [91][100/391]\tTime 0.056 (0.060)\tData 0.002 (0.004)\tLoss 0.8787 (1.0222)\tPrec 70.312% (63.204%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9496 (1.0276)\tPrec 67.969% (63.211%)\n",
      "Epoch: [91][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8932 (1.0328)\tPrec 71.875% (63.133%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 1.0682 (1.0682)\tPrec 62.500% (62.500%)\n",
      " * Prec 61.680% \n",
      "best acc: 64.420000\n",
      "Epoch: [92][0/391]\tTime 0.265 (0.265)\tData 0.217 (0.217)\tLoss 1.0545 (1.0545)\tPrec 64.062% (64.062%)\n",
      "Epoch: [92][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.8778 (1.0397)\tPrec 71.094% (62.910%)\n",
      "Epoch: [92][200/391]\tTime 0.061 (0.058)\tData 0.002 (0.003)\tLoss 0.9451 (1.0408)\tPrec 67.969% (62.613%)\n",
      "Epoch: [92][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.8585 (1.0342)\tPrec 67.188% (62.866%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.9539 (0.9539)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.840% \n",
      "best acc: 64.840000\n",
      "Epoch: [93][0/391]\tTime 0.268 (0.268)\tData 0.221 (0.221)\tLoss 1.0055 (1.0055)\tPrec 62.500% (62.500%)\n",
      "Epoch: [93][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.8727 (0.9919)\tPrec 72.656% (64.658%)\n",
      "Epoch: [93][200/391]\tTime 0.053 (0.058)\tData 0.002 (0.003)\tLoss 0.9345 (1.0176)\tPrec 67.969% (64.160%)\n",
      "Epoch: [93][300/391]\tTime 0.064 (0.058)\tData 0.002 (0.003)\tLoss 0.9243 (1.0189)\tPrec 67.188% (63.839%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.8713 (0.8713)\tPrec 70.312% (70.312%)\n",
      " * Prec 64.260% \n",
      "best acc: 64.840000\n",
      "Epoch: [94][0/391]\tTime 0.266 (0.266)\tData 0.218 (0.218)\tLoss 0.7907 (0.7907)\tPrec 69.531% (69.531%)\n",
      "Epoch: [94][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.1536 (1.0143)\tPrec 60.156% (63.738%)\n",
      "Epoch: [94][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0229 (1.0182)\tPrec 60.156% (63.608%)\n",
      "Epoch: [94][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.8605 (1.0156)\tPrec 70.312% (63.671%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.230 (0.230)\tLoss 1.0710 (1.0710)\tPrec 61.719% (61.719%)\n",
      " * Prec 62.370% \n",
      "best acc: 64.840000\n",
      "Epoch: [95][0/391]\tTime 0.265 (0.265)\tData 0.215 (0.215)\tLoss 1.0038 (1.0038)\tPrec 65.625% (65.625%)\n",
      "Epoch: [95][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.004)\tLoss 0.9662 (0.9973)\tPrec 62.500% (64.325%)\n",
      "Epoch: [95][200/391]\tTime 0.057 (0.058)\tData 0.001 (0.003)\tLoss 0.8853 (1.0144)\tPrec 64.844% (63.654%)\n",
      "Epoch: [95][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9656 (1.0203)\tPrec 64.062% (63.447%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.8824 (0.8824)\tPrec 65.625% (65.625%)\n",
      " * Prec 64.670% \n",
      "best acc: 64.840000\n",
      "Epoch: [96][0/391]\tTime 0.280 (0.280)\tData 0.233 (0.233)\tLoss 1.1622 (1.1622)\tPrec 57.812% (57.812%)\n",
      "Epoch: [96][100/391]\tTime 0.059 (0.060)\tData 0.002 (0.004)\tLoss 0.9718 (1.0118)\tPrec 60.938% (63.591%)\n",
      "Epoch: [96][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.9753 (1.0096)\tPrec 62.500% (63.884%)\n",
      "Epoch: [96][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.1658 (1.0099)\tPrec 58.594% (63.922%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.9321 (0.9321)\tPrec 64.844% (64.844%)\n",
      " * Prec 65.050% \n",
      "best acc: 65.050000\n",
      "Epoch: [97][0/391]\tTime 0.302 (0.302)\tData 0.247 (0.247)\tLoss 0.8842 (0.8842)\tPrec 64.062% (64.062%)\n",
      "Epoch: [97][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.0092 (0.9914)\tPrec 63.281% (64.503%)\n",
      "Epoch: [97][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9863 (1.0022)\tPrec 64.844% (64.062%)\n",
      "Epoch: [97][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 1.0429 (0.9980)\tPrec 61.719% (64.291%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.191 (0.191)\tLoss 0.8914 (0.8914)\tPrec 68.750% (68.750%)\n",
      " * Prec 64.630% \n",
      "best acc: 65.050000\n",
      "Epoch: [98][0/391]\tTime 0.289 (0.289)\tData 0.239 (0.239)\tLoss 0.9287 (0.9287)\tPrec 67.188% (67.188%)\n",
      "Epoch: [98][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 1.0660 (1.0048)\tPrec 58.594% (63.745%)\n",
      "Epoch: [98][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.9755 (0.9964)\tPrec 72.656% (64.257%)\n",
      "Epoch: [98][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.0462 (0.9993)\tPrec 62.500% (64.156%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.9698 (0.9698)\tPrec 66.406% (66.406%)\n",
      " * Prec 65.690% \n",
      "best acc: 65.690000\n",
      "Epoch: [99][0/391]\tTime 0.279 (0.279)\tData 0.222 (0.222)\tLoss 1.1317 (1.1317)\tPrec 60.156% (60.156%)\n",
      "Epoch: [99][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.8899 (0.9843)\tPrec 67.969% (65.014%)\n",
      "Epoch: [99][200/391]\tTime 0.056 (0.059)\tData 0.002 (0.003)\tLoss 1.2550 (0.9949)\tPrec 57.031% (64.813%)\n",
      "Epoch: [99][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.0363 (0.9953)\tPrec 65.625% (64.654%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.227 (0.227)\tLoss 0.9930 (0.9930)\tPrec 63.281% (63.281%)\n",
      " * Prec 64.380% \n",
      "best acc: 65.690000\n",
      "Epoch: [100][0/391]\tTime 0.269 (0.269)\tData 0.219 (0.219)\tLoss 1.1154 (1.1154)\tPrec 57.031% (57.031%)\n",
      "Epoch: [100][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.0587 (1.0152)\tPrec 65.625% (63.753%)\n",
      "Epoch: [100][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9440 (1.0073)\tPrec 62.500% (63.981%)\n",
      "Epoch: [100][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.8462 (0.9980)\tPrec 68.750% (64.483%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.9816 (0.9816)\tPrec 61.719% (61.719%)\n",
      " * Prec 64.780% \n",
      "best acc: 65.690000\n",
      "Epoch: [101][0/391]\tTime 0.287 (0.287)\tData 0.231 (0.231)\tLoss 1.0892 (1.0892)\tPrec 64.062% (64.062%)\n",
      "Epoch: [101][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 0.8717 (1.0005)\tPrec 72.656% (64.356%)\n",
      "Epoch: [101][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 0.9124 (0.9943)\tPrec 65.625% (64.568%)\n",
      "Epoch: [101][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.1475 (1.0040)\tPrec 59.375% (64.260%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.9298 (0.9298)\tPrec 65.625% (65.625%)\n",
      " * Prec 64.900% \n",
      "best acc: 65.690000\n",
      "Epoch: [102][0/391]\tTime 0.259 (0.259)\tData 0.215 (0.215)\tLoss 1.0116 (1.0116)\tPrec 64.844% (64.844%)\n",
      "Epoch: [102][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 0.9276 (0.9766)\tPrec 68.750% (65.339%)\n",
      "Epoch: [102][200/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.0594 (0.9874)\tPrec 65.625% (64.692%)\n",
      "Epoch: [102][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 0.9086 (0.9873)\tPrec 68.750% (64.880%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 1.1407 (1.1407)\tPrec 60.156% (60.156%)\n",
      " * Prec 60.300% \n",
      "best acc: 65.690000\n",
      "Epoch: [103][0/391]\tTime 0.273 (0.273)\tData 0.230 (0.230)\tLoss 1.1473 (1.1473)\tPrec 59.375% (59.375%)\n",
      "Epoch: [103][100/391]\tTime 0.057 (0.060)\tData 0.001 (0.004)\tLoss 0.9952 (1.0493)\tPrec 67.969% (62.113%)\n",
      "Epoch: [103][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.9488 (1.0107)\tPrec 65.625% (63.592%)\n",
      "Epoch: [103][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.9538 (1.0051)\tPrec 62.500% (63.948%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.194 (0.194)\tLoss 0.8597 (0.8597)\tPrec 68.750% (68.750%)\n",
      " * Prec 66.080% \n",
      "best acc: 66.080000\n",
      "Epoch: [104][0/391]\tTime 0.267 (0.267)\tData 0.218 (0.218)\tLoss 0.9318 (0.9318)\tPrec 62.500% (62.500%)\n",
      "Epoch: [104][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.9815 (0.9693)\tPrec 62.500% (65.401%)\n",
      "Epoch: [104][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8482 (0.9578)\tPrec 67.188% (65.827%)\n",
      "Epoch: [104][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.1175 (0.9631)\tPrec 60.938% (65.612%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.9543 (0.9543)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.480% \n",
      "best acc: 66.080000\n",
      "Epoch: [105][0/391]\tTime 0.267 (0.267)\tData 0.219 (0.219)\tLoss 0.8898 (0.8898)\tPrec 64.844% (64.844%)\n",
      "Epoch: [105][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.8861 (0.9865)\tPrec 66.406% (64.735%)\n",
      "Epoch: [105][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.8911 (0.9849)\tPrec 66.406% (64.813%)\n",
      "Epoch: [105][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.9539 (0.9937)\tPrec 68.750% (64.665%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.234 (0.234)\tLoss 0.8988 (0.8988)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.940% \n",
      "best acc: 66.080000\n",
      "Epoch: [106][0/391]\tTime 0.253 (0.253)\tData 0.208 (0.208)\tLoss 1.1173 (1.1173)\tPrec 64.062% (64.062%)\n",
      "Epoch: [106][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 1.0457 (0.9821)\tPrec 63.281% (64.906%)\n",
      "Epoch: [106][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.0053 (0.9786)\tPrec 68.750% (65.077%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [106][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 1.0168 (0.9805)\tPrec 63.281% (64.932%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.9407 (0.9407)\tPrec 69.531% (69.531%)\n",
      " * Prec 63.370% \n",
      "best acc: 66.080000\n",
      "Epoch: [107][0/391]\tTime 0.266 (0.266)\tData 0.218 (0.218)\tLoss 0.8885 (0.8885)\tPrec 69.531% (69.531%)\n",
      "Epoch: [107][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.9024 (0.9924)\tPrec 71.094% (64.581%)\n",
      "Epoch: [107][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.1210 (0.9718)\tPrec 60.938% (65.372%)\n",
      "Epoch: [107][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 1.0459 (0.9693)\tPrec 59.375% (65.376%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.8481 (0.8481)\tPrec 72.656% (72.656%)\n",
      " * Prec 64.850% \n",
      "best acc: 66.080000\n",
      "Epoch: [108][0/391]\tTime 0.264 (0.264)\tData 0.213 (0.213)\tLoss 0.9648 (0.9648)\tPrec 65.625% (65.625%)\n",
      "Epoch: [108][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.004)\tLoss 1.0666 (1.0259)\tPrec 60.156% (62.833%)\n",
      "Epoch: [108][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.0217 (1.0065)\tPrec 67.188% (63.891%)\n",
      "Epoch: [108][300/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.8963 (1.0023)\tPrec 66.406% (63.985%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.8960 (0.8960)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.300% \n",
      "best acc: 66.080000\n",
      "Epoch: [109][0/391]\tTime 0.278 (0.278)\tData 0.230 (0.230)\tLoss 1.0160 (1.0160)\tPrec 61.719% (61.719%)\n",
      "Epoch: [109][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.004)\tLoss 0.8723 (0.9845)\tPrec 68.750% (64.403%)\n",
      "Epoch: [109][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 0.8702 (0.9816)\tPrec 69.531% (64.455%)\n",
      "Epoch: [109][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.8957 (0.9851)\tPrec 69.531% (64.473%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.9137 (0.9137)\tPrec 65.625% (65.625%)\n",
      " * Prec 64.750% \n",
      "best acc: 66.080000\n",
      "Epoch: [110][0/391]\tTime 0.294 (0.294)\tData 0.247 (0.247)\tLoss 0.8059 (0.8059)\tPrec 75.781% (75.781%)\n",
      "Epoch: [110][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 1.0156 (0.9893)\tPrec 62.500% (64.472%)\n",
      "Epoch: [110][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9829 (0.9821)\tPrec 68.750% (64.855%)\n",
      "Epoch: [110][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.9380 (0.9862)\tPrec 65.625% (64.626%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 0.8951 (0.8951)\tPrec 67.969% (67.969%)\n",
      " * Prec 65.510% \n",
      "best acc: 66.080000\n",
      "Epoch: [111][0/391]\tTime 0.314 (0.314)\tData 0.266 (0.266)\tLoss 1.0942 (1.0942)\tPrec 64.844% (64.844%)\n",
      "Epoch: [111][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.2175 (0.9963)\tPrec 59.375% (64.403%)\n",
      "Epoch: [111][200/391]\tTime 0.052 (0.058)\tData 0.002 (0.003)\tLoss 1.0142 (0.9797)\tPrec 60.938% (65.065%)\n",
      "Epoch: [111][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.9475 (0.9733)\tPrec 70.312% (65.259%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.194 (0.194)\tLoss 0.8973 (0.8973)\tPrec 62.500% (62.500%)\n",
      " * Prec 64.310% \n",
      "best acc: 66.080000\n",
      "Epoch: [112][0/391]\tTime 0.235 (0.235)\tData 0.191 (0.191)\tLoss 1.0867 (1.0867)\tPrec 61.719% (61.719%)\n",
      "Epoch: [112][100/391]\tTime 0.060 (0.058)\tData 0.002 (0.004)\tLoss 1.1163 (1.0027)\tPrec 63.281% (63.892%)\n",
      "Epoch: [112][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.8825 (0.9824)\tPrec 67.188% (64.793%)\n",
      "Epoch: [112][300/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.9904 (0.9853)\tPrec 61.719% (64.756%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.8575 (0.8575)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.450% \n",
      "best acc: 66.080000\n",
      "Epoch: [113][0/391]\tTime 0.247 (0.247)\tData 0.199 (0.199)\tLoss 0.8766 (0.8766)\tPrec 66.406% (66.406%)\n",
      "Epoch: [113][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 1.0227 (0.9572)\tPrec 63.281% (65.231%)\n",
      "Epoch: [113][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.7526 (0.9567)\tPrec 77.344% (65.438%)\n",
      "Epoch: [113][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.9862 (0.9544)\tPrec 62.500% (65.672%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.9291 (0.9291)\tPrec 62.500% (62.500%)\n",
      " * Prec 65.450% \n",
      "best acc: 66.080000\n",
      "Epoch: [114][0/391]\tTime 0.272 (0.272)\tData 0.231 (0.231)\tLoss 0.8935 (0.8935)\tPrec 66.406% (66.406%)\n",
      "Epoch: [114][100/391]\tTime 0.052 (0.059)\tData 0.002 (0.004)\tLoss 1.0078 (0.9934)\tPrec 61.719% (64.604%)\n",
      "Epoch: [114][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9706 (0.9988)\tPrec 67.188% (64.389%)\n",
      "Epoch: [114][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.9854 (0.9903)\tPrec 64.844% (64.771%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.8800 (0.8800)\tPrec 65.625% (65.625%)\n",
      " * Prec 65.130% \n",
      "best acc: 66.080000\n",
      "Epoch: [115][0/391]\tTime 0.246 (0.246)\tData 0.199 (0.199)\tLoss 0.9231 (0.9231)\tPrec 67.969% (67.969%)\n",
      "Epoch: [115][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.004)\tLoss 1.0364 (0.9841)\tPrec 67.188% (64.658%)\n",
      "Epoch: [115][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 1.1977 (0.9756)\tPrec 53.906% (65.038%)\n",
      "Epoch: [115][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 0.8344 (0.9672)\tPrec 76.562% (65.319%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.185 (0.185)\tLoss 0.8801 (0.8801)\tPrec 71.875% (71.875%)\n",
      " * Prec 66.630% \n",
      "best acc: 66.630000\n",
      "Epoch: [116][0/391]\tTime 0.258 (0.258)\tData 0.217 (0.217)\tLoss 1.0236 (1.0236)\tPrec 64.844% (64.844%)\n",
      "Epoch: [116][100/391]\tTime 0.054 (0.059)\tData 0.003 (0.004)\tLoss 1.0417 (0.9444)\tPrec 63.281% (65.958%)\n",
      "Epoch: [116][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0112 (0.9522)\tPrec 61.719% (66.080%)\n",
      "Epoch: [116][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.9022 (0.9521)\tPrec 69.531% (66.178%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.8324 (0.8324)\tPrec 67.969% (67.969%)\n",
      " * Prec 67.580% \n",
      "best acc: 67.580000\n",
      "Epoch: [117][0/391]\tTime 0.233 (0.233)\tData 0.184 (0.184)\tLoss 0.8478 (0.8478)\tPrec 74.219% (74.219%)\n",
      "Epoch: [117][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.8170 (0.9538)\tPrec 75.000% (66.252%)\n",
      "Epoch: [117][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0161 (0.9670)\tPrec 62.500% (65.920%)\n",
      "Epoch: [117][300/391]\tTime 0.057 (0.057)\tData 0.005 (0.002)\tLoss 0.7623 (0.9659)\tPrec 72.656% (65.913%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.8013 (0.8013)\tPrec 66.406% (66.406%)\n",
      " * Prec 67.160% \n",
      "best acc: 67.580000\n",
      "Epoch: [118][0/391]\tTime 0.247 (0.247)\tData 0.206 (0.206)\tLoss 1.0136 (1.0136)\tPrec 66.406% (66.406%)\n",
      "Epoch: [118][100/391]\tTime 0.057 (0.059)\tData 0.003 (0.004)\tLoss 1.0085 (0.9601)\tPrec 58.594% (66.182%)\n",
      "Epoch: [118][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 0.9195 (0.9660)\tPrec 64.844% (65.683%)\n",
      "Epoch: [118][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.003)\tLoss 0.9814 (0.9562)\tPrec 68.750% (66.040%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.8936 (0.8936)\tPrec 68.750% (68.750%)\n",
      " * Prec 64.430% \n",
      "best acc: 67.580000\n",
      "Epoch: [119][0/391]\tTime 0.259 (0.259)\tData 0.217 (0.217)\tLoss 1.1468 (1.1468)\tPrec 60.938% (60.938%)\n",
      "Epoch: [119][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.8604 (0.9361)\tPrec 66.406% (66.801%)\n",
      "Epoch: [119][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.9944 (0.9407)\tPrec 63.281% (66.356%)\n",
      "Epoch: [119][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.9237 (0.9498)\tPrec 67.969% (66.251%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.8950 (0.8950)\tPrec 70.312% (70.312%)\n",
      " * Prec 65.950% \n",
      "best acc: 67.580000\n",
      "Epoch: [120][0/391]\tTime 0.224 (0.224)\tData 0.184 (0.184)\tLoss 0.8714 (0.8714)\tPrec 68.750% (68.750%)\n",
      "Epoch: [120][100/391]\tTime 0.057 (0.058)\tData 0.002 (0.004)\tLoss 0.9564 (0.9768)\tPrec 66.406% (65.524%)\n",
      "Epoch: [120][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8076 (0.9633)\tPrec 69.531% (65.870%)\n",
      "Epoch: [120][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 0.8710 (0.9356)\tPrec 67.188% (66.725%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.8338 (0.8338)\tPrec 67.969% (67.969%)\n",
      " * Prec 66.340% \n",
      "best acc: 67.580000\n",
      "Epoch: [121][0/391]\tTime 0.260 (0.260)\tData 0.214 (0.214)\tLoss 0.9144 (0.9144)\tPrec 66.406% (66.406%)\n",
      "Epoch: [121][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.7732 (0.9406)\tPrec 71.094% (66.344%)\n",
      "Epoch: [121][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 1.1360 (0.9360)\tPrec 54.688% (66.628%)\n",
      "Epoch: [121][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.003)\tLoss 0.8113 (0.9380)\tPrec 69.531% (66.565%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation starts\n",
      "Test: [0/79]\tTime 0.282 (0.282)\tLoss 0.8945 (0.8945)\tPrec 66.406% (66.406%)\n",
      " * Prec 66.700% \n",
      "best acc: 67.580000\n",
      "Epoch: [122][0/391]\tTime 0.225 (0.225)\tData 0.185 (0.185)\tLoss 0.8446 (0.8446)\tPrec 71.875% (71.875%)\n",
      "Epoch: [122][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 1.0417 (0.9471)\tPrec 64.062% (66.252%)\n",
      "Epoch: [122][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9645 (0.9542)\tPrec 68.750% (66.130%)\n",
      "Epoch: [122][300/391]\tTime 0.059 (0.058)\tData 0.002 (0.002)\tLoss 0.9108 (0.9400)\tPrec 66.406% (66.580%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.8306 (0.8306)\tPrec 70.312% (70.312%)\n",
      " * Prec 67.650% \n",
      "best acc: 67.650000\n",
      "Epoch: [123][0/391]\tTime 0.302 (0.302)\tData 0.249 (0.249)\tLoss 0.9504 (0.9504)\tPrec 71.094% (71.094%)\n",
      "Epoch: [123][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 0.9112 (0.9371)\tPrec 66.406% (66.507%)\n",
      "Epoch: [123][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8702 (0.9304)\tPrec 64.062% (66.772%)\n",
      "Epoch: [123][300/391]\tTime 0.060 (0.057)\tData 0.002 (0.003)\tLoss 0.9901 (0.9317)\tPrec 64.062% (66.718%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.9000 (0.9000)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.650% \n",
      "best acc: 67.650000\n",
      "Epoch: [124][0/391]\tTime 0.249 (0.249)\tData 0.195 (0.195)\tLoss 0.9623 (0.9623)\tPrec 64.062% (64.062%)\n",
      "Epoch: [124][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.9881 (0.9626)\tPrec 61.719% (66.128%)\n",
      "Epoch: [124][200/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 0.8877 (0.9534)\tPrec 67.188% (66.282%)\n",
      "Epoch: [124][300/391]\tTime 0.055 (0.059)\tData 0.002 (0.002)\tLoss 0.8207 (0.9470)\tPrec 76.562% (66.520%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.8922 (0.8922)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.270% \n",
      "best acc: 67.650000\n",
      "Epoch: [125][0/391]\tTime 0.255 (0.255)\tData 0.211 (0.211)\tLoss 0.8378 (0.8378)\tPrec 71.094% (71.094%)\n",
      "Epoch: [125][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.9554 (0.9173)\tPrec 68.750% (67.211%)\n",
      "Epoch: [125][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.8279 (0.9200)\tPrec 66.406% (67.086%)\n",
      "Epoch: [125][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.9708 (0.9111)\tPrec 71.094% (67.650%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.239 (0.239)\tLoss 0.7806 (0.7806)\tPrec 72.656% (72.656%)\n",
      " * Prec 67.350% \n",
      "best acc: 67.650000\n",
      "Epoch: [126][0/391]\tTime 0.228 (0.228)\tData 0.188 (0.188)\tLoss 0.8923 (0.8923)\tPrec 66.406% (66.406%)\n",
      "Epoch: [126][100/391]\tTime 0.051 (0.058)\tData 0.002 (0.004)\tLoss 0.7341 (0.9017)\tPrec 71.094% (68.619%)\n",
      "Epoch: [126][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8695 (0.8962)\tPrec 66.406% (68.610%)\n",
      "Epoch: [126][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 0.7385 (0.8969)\tPrec 78.906% (68.498%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.8204 (0.8204)\tPrec 70.312% (70.312%)\n",
      " * Prec 67.980% \n",
      "best acc: 67.980000\n",
      "Epoch: [127][0/391]\tTime 0.220 (0.220)\tData 0.179 (0.179)\tLoss 0.8597 (0.8597)\tPrec 69.531% (69.531%)\n",
      "Epoch: [127][100/391]\tTime 0.061 (0.059)\tData 0.002 (0.004)\tLoss 0.9354 (0.8889)\tPrec 67.969% (68.704%)\n",
      "Epoch: [127][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9362 (0.8979)\tPrec 68.750% (68.140%)\n",
      "Epoch: [127][300/391]\tTime 0.063 (0.057)\tData 0.002 (0.002)\tLoss 0.8671 (0.9040)\tPrec 69.531% (67.868%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.181 (0.181)\tLoss 0.8604 (0.8604)\tPrec 68.750% (68.750%)\n",
      " * Prec 66.800% \n",
      "best acc: 67.980000\n",
      "Epoch: [128][0/391]\tTime 0.243 (0.243)\tData 0.197 (0.197)\tLoss 0.7583 (0.7583)\tPrec 71.875% (71.875%)\n",
      "Epoch: [128][100/391]\tTime 0.063 (0.059)\tData 0.004 (0.004)\tLoss 0.9818 (0.9402)\tPrec 67.188% (66.321%)\n",
      "Epoch: [128][200/391]\tTime 0.059 (0.058)\tData 0.004 (0.003)\tLoss 0.9987 (0.9239)\tPrec 67.188% (67.067%)\n",
      "Epoch: [128][300/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.8229 (0.9187)\tPrec 72.656% (67.359%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.7867 (0.7867)\tPrec 74.219% (74.219%)\n",
      " * Prec 67.390% \n",
      "best acc: 67.980000\n",
      "Epoch: [129][0/391]\tTime 0.240 (0.240)\tData 0.191 (0.191)\tLoss 0.9474 (0.9474)\tPrec 68.750% (68.750%)\n",
      "Epoch: [129][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 1.0217 (0.9277)\tPrec 64.062% (66.677%)\n",
      "Epoch: [129][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0298 (0.9180)\tPrec 67.188% (67.172%)\n",
      "Epoch: [129][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 0.8969 (0.9213)\tPrec 67.969% (67.097%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.9881 (0.9881)\tPrec 66.406% (66.406%)\n",
      " * Prec 65.590% \n",
      "best acc: 67.980000\n",
      "Epoch: [130][0/391]\tTime 0.243 (0.243)\tData 0.197 (0.197)\tLoss 0.9675 (0.9675)\tPrec 66.406% (66.406%)\n",
      "Epoch: [130][100/391]\tTime 0.057 (0.058)\tData 0.002 (0.004)\tLoss 0.8840 (0.9105)\tPrec 71.094% (67.481%)\n",
      "Epoch: [130][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.7761 (0.9086)\tPrec 72.656% (67.654%)\n",
      "Epoch: [130][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.8805 (0.9040)\tPrec 66.406% (67.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.8399 (0.8399)\tPrec 71.094% (71.094%)\n",
      " * Prec 68.930% \n",
      "best acc: 68.930000\n",
      "Epoch: [131][0/391]\tTime 0.282 (0.282)\tData 0.231 (0.231)\tLoss 1.0100 (1.0100)\tPrec 66.406% (66.406%)\n",
      "Epoch: [131][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.7713 (0.8735)\tPrec 74.219% (69.222%)\n",
      "Epoch: [131][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 1.0717 (0.8897)\tPrec 60.156% (68.738%)\n",
      "Epoch: [131][300/391]\tTime 0.060 (0.057)\tData 0.002 (0.003)\tLoss 1.0042 (0.8983)\tPrec 59.375% (68.379%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.8873 (0.8873)\tPrec 67.188% (67.188%)\n",
      " * Prec 68.570% \n",
      "best acc: 68.930000\n",
      "Epoch: [132][0/391]\tTime 0.271 (0.271)\tData 0.229 (0.229)\tLoss 0.7778 (0.7778)\tPrec 67.188% (67.188%)\n",
      "Epoch: [132][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.7172 (0.8885)\tPrec 76.562% (68.881%)\n",
      "Epoch: [132][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 0.8945 (0.8942)\tPrec 75.000% (68.645%)\n",
      "Epoch: [132][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.8021 (0.8922)\tPrec 70.312% (68.688%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.7592 (0.7592)\tPrec 69.531% (69.531%)\n",
      " * Prec 68.890% \n",
      "best acc: 68.930000\n",
      "Epoch: [133][0/391]\tTime 0.243 (0.243)\tData 0.204 (0.204)\tLoss 0.7595 (0.7595)\tPrec 68.750% (68.750%)\n",
      "Epoch: [133][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.004)\tLoss 0.9198 (0.8649)\tPrec 65.625% (68.912%)\n",
      "Epoch: [133][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.7738 (0.8671)\tPrec 71.875% (69.197%)\n",
      "Epoch: [133][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 0.7969 (0.8771)\tPrec 67.969% (68.895%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.7624 (0.7624)\tPrec 71.875% (71.875%)\n",
      " * Prec 68.740% \n",
      "best acc: 68.930000\n",
      "Epoch: [134][0/391]\tTime 0.278 (0.278)\tData 0.228 (0.228)\tLoss 0.8235 (0.8235)\tPrec 65.625% (65.625%)\n",
      "Epoch: [134][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.8801 (0.8665)\tPrec 65.625% (69.446%)\n",
      "Epoch: [134][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.8209 (0.8805)\tPrec 70.312% (69.139%)\n",
      "Epoch: [134][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.6916 (0.8775)\tPrec 75.781% (69.181%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.252 (0.252)\tLoss 0.8501 (0.8501)\tPrec 69.531% (69.531%)\n",
      " * Prec 68.300% \n",
      "best acc: 68.930000\n",
      "Epoch: [135][0/391]\tTime 0.288 (0.288)\tData 0.239 (0.239)\tLoss 0.7664 (0.7664)\tPrec 71.875% (71.875%)\n",
      "Epoch: [135][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.004)\tLoss 0.9952 (0.9136)\tPrec 60.938% (67.644%)\n",
      "Epoch: [135][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.7006 (0.9079)\tPrec 75.781% (67.980%)\n",
      "Epoch: [135][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9237 (0.9066)\tPrec 68.750% (68.054%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.7978 (0.7978)\tPrec 70.312% (70.312%)\n",
      " * Prec 68.560% \n",
      "best acc: 68.930000\n",
      "Epoch: [136][0/391]\tTime 0.246 (0.246)\tData 0.198 (0.198)\tLoss 0.8975 (0.8975)\tPrec 67.188% (67.188%)\n",
      "Epoch: [136][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 0.8849 (0.8943)\tPrec 71.875% (68.232%)\n",
      "Epoch: [136][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 0.9725 (0.9026)\tPrec 71.875% (68.458%)\n",
      "Epoch: [136][300/391]\tTime 0.061 (0.058)\tData 0.002 (0.002)\tLoss 0.9179 (0.9045)\tPrec 66.406% (68.259%)\n",
      "Validation starts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.7785 (0.7785)\tPrec 74.219% (74.219%)\n",
      " * Prec 67.050% \n",
      "best acc: 68.930000\n",
      "Epoch: [137][0/391]\tTime 0.267 (0.267)\tData 0.216 (0.216)\tLoss 0.9829 (0.9829)\tPrec 65.625% (65.625%)\n",
      "Epoch: [137][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.8910 (0.8968)\tPrec 69.531% (68.479%)\n",
      "Epoch: [137][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 1.0698 (0.9045)\tPrec 65.625% (68.272%)\n",
      "Epoch: [137][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.9343 (0.9014)\tPrec 64.062% (68.218%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.7719 (0.7719)\tPrec 73.438% (73.438%)\n",
      " * Prec 69.050% \n",
      "best acc: 69.050000\n",
      "Epoch: [138][0/391]\tTime 0.243 (0.243)\tData 0.200 (0.200)\tLoss 0.7815 (0.7815)\tPrec 71.875% (71.875%)\n",
      "Epoch: [138][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.9026 (0.8803)\tPrec 67.969% (68.851%)\n",
      "Epoch: [138][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 0.7647 (0.8672)\tPrec 70.312% (69.181%)\n",
      "Epoch: [138][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8445 (0.8712)\tPrec 67.188% (69.093%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.8249 (0.8249)\tPrec 69.531% (69.531%)\n",
      " * Prec 69.640% \n",
      "best acc: 69.640000\n",
      "Epoch: [139][0/391]\tTime 0.279 (0.279)\tData 0.231 (0.231)\tLoss 0.7335 (0.7335)\tPrec 71.875% (71.875%)\n",
      "Epoch: [139][100/391]\tTime 0.057 (0.058)\tData 0.002 (0.004)\tLoss 0.7013 (0.8397)\tPrec 72.656% (69.841%)\n",
      "Epoch: [139][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 0.9699 (0.8494)\tPrec 67.188% (69.846%)\n",
      "Epoch: [139][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6630 (0.8556)\tPrec 78.125% (69.734%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.8434 (0.8434)\tPrec 69.531% (69.531%)\n",
      " * Prec 69.670% \n",
      "best acc: 69.670000\n",
      "Epoch: [140][0/391]\tTime 0.249 (0.249)\tData 0.200 (0.200)\tLoss 1.0110 (1.0110)\tPrec 58.594% (58.594%)\n",
      "Epoch: [140][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.8782 (0.8637)\tPrec 65.625% (69.415%)\n",
      "Epoch: [140][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.8593 (0.8647)\tPrec 69.531% (69.302%)\n",
      "Epoch: [140][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8647 (0.8653)\tPrec 71.094% (69.451%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.9280 (0.9280)\tPrec 64.062% (64.062%)\n",
      " * Prec 67.090% \n",
      "best acc: 69.670000\n",
      "Epoch: [141][0/391]\tTime 0.241 (0.241)\tData 0.198 (0.198)\tLoss 1.0877 (1.0877)\tPrec 62.500% (62.500%)\n",
      "Epoch: [141][100/391]\tTime 0.052 (0.059)\tData 0.002 (0.004)\tLoss 0.9860 (0.9102)\tPrec 59.375% (67.760%)\n",
      "Epoch: [141][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 0.7729 (0.8941)\tPrec 71.094% (68.381%)\n",
      "Epoch: [141][300/391]\tTime 0.058 (0.058)\tData 0.003 (0.002)\tLoss 0.8385 (0.8796)\tPrec 72.656% (69.028%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.8380 (0.8380)\tPrec 68.750% (68.750%)\n",
      " * Prec 67.880% \n",
      "best acc: 69.670000\n",
      "Epoch: [142][0/391]\tTime 0.255 (0.255)\tData 0.216 (0.216)\tLoss 0.8805 (0.8805)\tPrec 71.094% (71.094%)\n",
      "Epoch: [142][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.8025 (0.8786)\tPrec 71.875% (69.090%)\n",
      "Epoch: [142][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 1.0707 (0.8844)\tPrec 67.969% (68.921%)\n",
      "Epoch: [142][300/391]\tTime 0.059 (0.058)\tData 0.002 (0.002)\tLoss 0.7297 (0.8944)\tPrec 76.562% (68.568%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.246 (0.246)\tLoss 0.8456 (0.8456)\tPrec 71.094% (71.094%)\n",
      " * Prec 65.050% \n",
      "best acc: 69.670000\n",
      "Epoch: [143][0/391]\tTime 0.263 (0.263)\tData 0.216 (0.216)\tLoss 0.9430 (0.9430)\tPrec 69.531% (69.531%)\n",
      "Epoch: [143][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 0.8176 (0.8887)\tPrec 71.094% (68.796%)\n",
      "Epoch: [143][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.9946 (0.8962)\tPrec 67.188% (68.513%)\n",
      "Epoch: [143][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 0.9522 (0.8992)\tPrec 67.969% (68.280%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.8004 (0.8004)\tPrec 74.219% (74.219%)\n",
      " * Prec 69.270% \n",
      "best acc: 69.670000\n",
      "Epoch: [144][0/391]\tTime 0.251 (0.251)\tData 0.203 (0.203)\tLoss 0.9067 (0.9067)\tPrec 65.625% (65.625%)\n",
      "Epoch: [144][100/391]\tTime 0.059 (0.061)\tData 0.002 (0.004)\tLoss 0.8645 (0.8827)\tPrec 64.844% (68.611%)\n",
      "Epoch: [144][200/391]\tTime 0.062 (0.060)\tData 0.002 (0.003)\tLoss 0.7310 (0.8767)\tPrec 71.875% (68.874%)\n",
      "Epoch: [144][300/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 0.9079 (0.8815)\tPrec 72.656% (68.662%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.429 (0.429)\tLoss 0.8162 (0.8162)\tPrec 71.875% (71.875%)\n",
      " * Prec 68.120% \n",
      "best acc: 69.670000\n",
      "Epoch: [145][0/391]\tTime 0.218 (0.218)\tData 0.173 (0.173)\tLoss 0.9023 (0.9023)\tPrec 68.750% (68.750%)\n",
      "Epoch: [145][100/391]\tTime 0.058 (0.058)\tData 0.002 (0.004)\tLoss 0.8340 (0.9085)\tPrec 69.531% (67.969%)\n",
      "Epoch: [145][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.9086 (0.8876)\tPrec 67.188% (68.738%)\n",
      "Epoch: [145][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.002)\tLoss 0.9367 (0.8888)\tPrec 67.188% (68.706%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.7879 (0.7879)\tPrec 72.656% (72.656%)\n",
      " * Prec 69.580% \n",
      "best acc: 69.670000\n",
      "Epoch: [146][0/391]\tTime 0.316 (0.316)\tData 0.270 (0.270)\tLoss 0.7756 (0.7756)\tPrec 74.219% (74.219%)\n",
      "Epoch: [146][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.005)\tLoss 0.8738 (0.8661)\tPrec 71.875% (69.779%)\n",
      "Epoch: [146][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.8390 (0.8602)\tPrec 74.219% (69.994%)\n",
      "Epoch: [146][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.8722 (0.8531)\tPrec 64.062% (70.193%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.7998 (0.7998)\tPrec 68.750% (68.750%)\n",
      " * Prec 68.360% \n",
      "best acc: 69.670000\n",
      "Epoch: [147][0/391]\tTime 0.255 (0.255)\tData 0.213 (0.213)\tLoss 0.8661 (0.8661)\tPrec 71.094% (71.094%)\n",
      "Epoch: [147][100/391]\tTime 0.060 (0.060)\tData 0.002 (0.004)\tLoss 0.8171 (0.8834)\tPrec 69.531% (68.851%)\n",
      "Epoch: [147][200/391]\tTime 0.064 (0.059)\tData 0.002 (0.003)\tLoss 0.8266 (0.8783)\tPrec 67.188% (69.205%)\n",
      "Epoch: [147][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8744 (0.8884)\tPrec 68.750% (68.856%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.8671 (0.8671)\tPrec 67.188% (67.188%)\n",
      " * Prec 68.670% \n",
      "best acc: 69.670000\n",
      "Epoch: [148][0/391]\tTime 0.252 (0.252)\tData 0.204 (0.204)\tLoss 1.0182 (1.0182)\tPrec 66.406% (66.406%)\n",
      "Epoch: [148][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.9748 (0.8738)\tPrec 67.969% (69.106%)\n",
      "Epoch: [148][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.8887 (0.8880)\tPrec 67.188% (68.606%)\n",
      "Epoch: [148][300/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.7995 (0.9013)\tPrec 73.438% (68.397%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.7840 (0.7840)\tPrec 74.219% (74.219%)\n",
      " * Prec 69.820% \n",
      "best acc: 69.820000\n",
      "Epoch: [149][0/391]\tTime 0.252 (0.252)\tData 0.209 (0.209)\tLoss 0.9102 (0.9102)\tPrec 68.750% (68.750%)\n",
      "Epoch: [149][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.8764 (0.8567)\tPrec 68.750% (69.732%)\n",
      "Epoch: [149][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.8047 (0.8565)\tPrec 68.750% (69.803%)\n",
      "Epoch: [149][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 1.0015 (0.8571)\tPrec 60.938% (69.658%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.8332 (0.8332)\tPrec 69.531% (69.531%)\n",
      " * Prec 68.970% \n",
      "best acc: 69.820000\n",
      "Epoch: [150][0/391]\tTime 0.261 (0.261)\tData 0.214 (0.214)\tLoss 0.8651 (0.8651)\tPrec 71.875% (71.875%)\n",
      "Epoch: [150][100/391]\tTime 0.064 (0.059)\tData 0.002 (0.004)\tLoss 0.9465 (0.8229)\tPrec 66.406% (70.421%)\n",
      "Epoch: [150][200/391]\tTime 0.057 (0.058)\tData 0.003 (0.003)\tLoss 0.5397 (0.8136)\tPrec 80.469% (71.218%)\n",
      "Epoch: [150][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6913 (0.8135)\tPrec 75.000% (71.166%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.6956 (0.6956)\tPrec 73.438% (73.438%)\n",
      " * Prec 72.320% \n",
      "best acc: 72.320000\n",
      "Epoch: [151][0/391]\tTime 0.247 (0.247)\tData 0.208 (0.208)\tLoss 0.6930 (0.6930)\tPrec 77.344% (77.344%)\n",
      "Epoch: [151][100/391]\tTime 0.058 (0.061)\tData 0.002 (0.004)\tLoss 0.8403 (0.7825)\tPrec 69.531% (72.440%)\n",
      "Epoch: [151][200/391]\tTime 0.057 (0.059)\tData 0.002 (0.003)\tLoss 0.8461 (0.7813)\tPrec 70.312% (72.407%)\n",
      "Epoch: [151][300/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 0.6922 (0.7806)\tPrec 73.438% (72.488%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.6995 (0.6995)\tPrec 74.219% (74.219%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec 72.910% \n",
      "best acc: 72.910000\n",
      "Epoch: [152][0/391]\tTime 0.261 (0.261)\tData 0.218 (0.218)\tLoss 0.7342 (0.7342)\tPrec 75.781% (75.781%)\n",
      "Epoch: [152][100/391]\tTime 0.059 (0.060)\tData 0.002 (0.004)\tLoss 0.7376 (0.7536)\tPrec 71.875% (73.352%)\n",
      "Epoch: [152][200/391]\tTime 0.057 (0.059)\tData 0.002 (0.003)\tLoss 0.7750 (0.7598)\tPrec 74.219% (72.870%)\n",
      "Epoch: [152][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8527 (0.7613)\tPrec 67.969% (72.934%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.6548 (0.6548)\tPrec 72.656% (72.656%)\n",
      " * Prec 73.580% \n",
      "best acc: 73.580000\n",
      "Epoch: [153][0/391]\tTime 0.243 (0.243)\tData 0.195 (0.195)\tLoss 0.7395 (0.7395)\tPrec 71.875% (71.875%)\n",
      "Epoch: [153][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.6550 (0.7467)\tPrec 71.875% (73.360%)\n",
      "Epoch: [153][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8375 (0.7634)\tPrec 69.531% (72.870%)\n",
      "Epoch: [153][300/391]\tTime 0.057 (0.057)\tData 0.001 (0.002)\tLoss 0.7881 (0.7568)\tPrec 71.875% (73.204%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.6390 (0.6390)\tPrec 77.344% (77.344%)\n",
      " * Prec 74.140% \n",
      "best acc: 74.140000\n",
      "Epoch: [154][0/391]\tTime 0.265 (0.265)\tData 0.217 (0.217)\tLoss 0.8299 (0.8299)\tPrec 68.750% (68.750%)\n",
      "Epoch: [154][100/391]\tTime 0.053 (0.059)\tData 0.002 (0.004)\tLoss 0.8295 (0.7608)\tPrec 64.844% (73.399%)\n",
      "Epoch: [154][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 0.8337 (0.7520)\tPrec 70.312% (73.636%)\n",
      "Epoch: [154][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6753 (0.7489)\tPrec 72.656% (73.739%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 0.6527 (0.6527)\tPrec 75.781% (75.781%)\n",
      " * Prec 74.170% \n",
      "best acc: 74.170000\n",
      "Epoch: [155][0/391]\tTime 0.231 (0.231)\tData 0.187 (0.187)\tLoss 0.6509 (0.6509)\tPrec 75.000% (75.000%)\n",
      "Epoch: [155][100/391]\tTime 0.058 (0.058)\tData 0.002 (0.004)\tLoss 0.6953 (0.7517)\tPrec 77.344% (73.113%)\n",
      "Epoch: [155][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.5931 (0.7436)\tPrec 82.031% (73.628%)\n",
      "Epoch: [155][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 0.6904 (0.7420)\tPrec 67.969% (73.720%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.6606 (0.6606)\tPrec 76.562% (76.562%)\n",
      " * Prec 73.840% \n",
      "best acc: 74.170000\n",
      "Epoch: [156][0/391]\tTime 0.241 (0.241)\tData 0.190 (0.190)\tLoss 0.8700 (0.8700)\tPrec 67.969% (67.969%)\n",
      "Epoch: [156][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.8582 (0.7312)\tPrec 72.656% (74.281%)\n",
      "Epoch: [156][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 0.7603 (0.7365)\tPrec 72.656% (74.195%)\n",
      "Epoch: [156][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6866 (0.7377)\tPrec 74.219% (74.138%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.221 (0.221)\tLoss 0.6745 (0.6745)\tPrec 76.562% (76.562%)\n",
      " * Prec 74.370% \n",
      "best acc: 74.370000\n",
      "Epoch: [157][0/391]\tTime 0.291 (0.291)\tData 0.246 (0.246)\tLoss 0.5676 (0.5676)\tPrec 78.906% (78.906%)\n",
      "Epoch: [157][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.004)\tLoss 0.6767 (0.7165)\tPrec 77.344% (74.466%)\n",
      "Epoch: [157][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8058 (0.7232)\tPrec 75.000% (74.413%)\n",
      "Epoch: [157][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 0.6142 (0.7252)\tPrec 74.219% (74.369%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.182 (0.182)\tLoss 0.6415 (0.6415)\tPrec 76.562% (76.562%)\n",
      " * Prec 74.540% \n",
      "best acc: 74.540000\n",
      "Epoch: [158][0/391]\tTime 0.258 (0.258)\tData 0.210 (0.210)\tLoss 0.9302 (0.9302)\tPrec 71.094% (71.094%)\n",
      "Epoch: [158][100/391]\tTime 0.057 (0.061)\tData 0.002 (0.004)\tLoss 0.8898 (0.7369)\tPrec 67.969% (74.033%)\n",
      "Epoch: [158][200/391]\tTime 0.058 (0.059)\tData 0.001 (0.003)\tLoss 0.7794 (0.7254)\tPrec 68.750% (74.363%)\n",
      "Epoch: [158][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.6071 (0.7250)\tPrec 81.250% (74.227%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 0.6164 (0.6164)\tPrec 76.562% (76.562%)\n",
      " * Prec 74.510% \n",
      "best acc: 74.540000\n",
      "Epoch: [159][0/391]\tTime 0.255 (0.255)\tData 0.208 (0.208)\tLoss 0.7857 (0.7857)\tPrec 69.531% (69.531%)\n",
      "Epoch: [159][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 0.7830 (0.7351)\tPrec 76.562% (73.832%)\n",
      "Epoch: [159][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.7223 (0.7229)\tPrec 73.438% (74.188%)\n",
      "Epoch: [159][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6734 (0.7245)\tPrec 76.562% (74.208%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.6410 (0.6410)\tPrec 75.781% (75.781%)\n",
      " * Prec 74.610% \n",
      "best acc: 74.610000\n",
      "Epoch: [160][0/391]\tTime 0.332 (0.332)\tData 0.277 (0.277)\tLoss 0.5999 (0.5999)\tPrec 80.469% (80.469%)\n",
      "Epoch: [160][100/391]\tTime 0.056 (0.060)\tData 0.002 (0.005)\tLoss 0.6890 (0.7309)\tPrec 78.906% (74.149%)\n",
      "Epoch: [160][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.5277 (0.7289)\tPrec 82.812% (74.487%)\n",
      "Epoch: [160][300/391]\tTime 0.056 (0.058)\tData 0.001 (0.003)\tLoss 0.7415 (0.7245)\tPrec 77.344% (74.548%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.6822 (0.6822)\tPrec 75.781% (75.781%)\n",
      " * Prec 74.550% \n",
      "best acc: 74.610000\n",
      "Epoch: [161][0/391]\tTime 0.297 (0.297)\tData 0.250 (0.250)\tLoss 0.6472 (0.6472)\tPrec 77.344% (77.344%)\n",
      "Epoch: [161][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 0.4856 (0.7194)\tPrec 82.812% (74.660%)\n",
      "Epoch: [161][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.7169 (0.7175)\tPrec 71.875% (74.755%)\n",
      "Epoch: [161][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6985 (0.7169)\tPrec 77.344% (74.530%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.6955 (0.6955)\tPrec 74.219% (74.219%)\n",
      " * Prec 74.900% \n",
      "best acc: 74.900000\n",
      "Epoch: [162][0/391]\tTime 0.266 (0.266)\tData 0.218 (0.218)\tLoss 0.7433 (0.7433)\tPrec 75.781% (75.781%)\n",
      "Epoch: [162][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.8989 (0.7186)\tPrec 68.750% (74.760%)\n",
      "Epoch: [162][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.7048 (0.7238)\tPrec 77.344% (74.580%)\n",
      "Epoch: [162][300/391]\tTime 0.062 (0.058)\tData 0.002 (0.003)\tLoss 0.5852 (0.7208)\tPrec 78.125% (74.707%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.6527 (0.6527)\tPrec 75.000% (75.000%)\n",
      " * Prec 74.830% \n",
      "best acc: 74.900000\n",
      "Epoch: [163][0/391]\tTime 0.268 (0.268)\tData 0.217 (0.217)\tLoss 0.6380 (0.6380)\tPrec 72.656% (72.656%)\n",
      "Epoch: [163][100/391]\tTime 0.059 (0.059)\tData 0.003 (0.004)\tLoss 0.6493 (0.7009)\tPrec 76.562% (75.031%)\n",
      "Epoch: [163][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.6883 (0.7057)\tPrec 75.000% (75.152%)\n",
      "Epoch: [163][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 0.7443 (0.7115)\tPrec 75.000% (74.894%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 0.6674 (0.6674)\tPrec 74.219% (74.219%)\n",
      " * Prec 75.370% \n",
      "best acc: 75.370000\n",
      "Epoch: [164][0/391]\tTime 0.271 (0.271)\tData 0.224 (0.224)\tLoss 0.6810 (0.6810)\tPrec 76.562% (76.562%)\n",
      "Epoch: [164][100/391]\tTime 0.058 (0.059)\tData 0.003 (0.004)\tLoss 0.6374 (0.7045)\tPrec 78.906% (75.278%)\n",
      "Epoch: [164][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.6183 (0.7080)\tPrec 75.781% (75.008%)\n",
      "Epoch: [164][300/391]\tTime 0.064 (0.057)\tData 0.002 (0.003)\tLoss 0.7248 (0.7130)\tPrec 75.000% (74.852%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.6016 (0.6016)\tPrec 78.906% (78.906%)\n",
      " * Prec 75.160% \n",
      "best acc: 75.370000\n",
      "Epoch: [165][0/391]\tTime 0.281 (0.281)\tData 0.242 (0.242)\tLoss 0.7374 (0.7374)\tPrec 74.219% (74.219%)\n",
      "Epoch: [165][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.004)\tLoss 0.8018 (0.7016)\tPrec 77.344% (75.340%)\n",
      "Epoch: [165][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.5687 (0.7037)\tPrec 78.125% (75.292%)\n",
      "Epoch: [165][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.7419 (0.7058)\tPrec 75.781% (75.327%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.5977 (0.5977)\tPrec 77.344% (77.344%)\n",
      " * Prec 75.500% \n",
      "best acc: 75.500000\n",
      "Epoch: [166][0/391]\tTime 0.276 (0.276)\tData 0.225 (0.225)\tLoss 0.7633 (0.7633)\tPrec 75.000% (75.000%)\n",
      "Epoch: [166][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.8506 (0.7067)\tPrec 70.312% (74.845%)\n",
      "Epoch: [166][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.6818 (0.7002)\tPrec 77.344% (75.051%)\n",
      "Epoch: [166][300/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 0.6247 (0.7016)\tPrec 78.125% (75.166%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.6221 (0.6221)\tPrec 75.000% (75.000%)\n",
      " * Prec 75.070% \n",
      "best acc: 75.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [167][0/391]\tTime 0.257 (0.257)\tData 0.215 (0.215)\tLoss 0.6394 (0.6394)\tPrec 75.781% (75.781%)\n",
      "Epoch: [167][100/391]\tTime 0.060 (0.059)\tData 0.002 (0.004)\tLoss 0.6926 (0.6939)\tPrec 76.562% (75.124%)\n",
      "Epoch: [167][200/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 0.7719 (0.6958)\tPrec 71.094% (75.463%)\n",
      "Epoch: [167][300/391]\tTime 0.061 (0.059)\tData 0.002 (0.003)\tLoss 0.8119 (0.6964)\tPrec 71.875% (75.395%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.6340 (0.6340)\tPrec 79.688% (79.688%)\n",
      " * Prec 75.990% \n",
      "best acc: 75.990000\n",
      "Epoch: [168][0/391]\tTime 0.302 (0.302)\tData 0.248 (0.248)\tLoss 0.6187 (0.6187)\tPrec 75.000% (75.000%)\n",
      "Epoch: [168][100/391]\tTime 0.057 (0.060)\tData 0.002 (0.004)\tLoss 0.8528 (0.7002)\tPrec 73.438% (75.155%)\n",
      "Epoch: [168][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8873 (0.7083)\tPrec 67.969% (74.848%)\n",
      "Epoch: [168][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.7705 (0.7037)\tPrec 69.531% (75.223%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.6244 (0.6244)\tPrec 81.250% (81.250%)\n",
      " * Prec 75.250% \n",
      "best acc: 75.990000\n",
      "Epoch: [169][0/391]\tTime 0.265 (0.265)\tData 0.219 (0.219)\tLoss 0.6608 (0.6608)\tPrec 80.469% (80.469%)\n",
      "Epoch: [169][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.8511 (0.6957)\tPrec 71.094% (75.681%)\n",
      "Epoch: [169][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.7725 (0.6923)\tPrec 76.562% (75.614%)\n",
      "Epoch: [169][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 0.8256 (0.6921)\tPrec 73.438% (75.550%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.6146 (0.6146)\tPrec 77.344% (77.344%)\n",
      " * Prec 75.520% \n",
      "best acc: 75.990000\n",
      "Epoch: [170][0/391]\tTime 0.286 (0.286)\tData 0.241 (0.241)\tLoss 0.6236 (0.6236)\tPrec 78.125% (78.125%)\n",
      "Epoch: [170][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.5746 (0.6795)\tPrec 84.375% (75.712%)\n",
      "Epoch: [170][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.6665 (0.6915)\tPrec 77.344% (75.303%)\n",
      "Epoch: [170][300/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.6617 (0.6907)\tPrec 75.000% (75.436%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.6194 (0.6194)\tPrec 76.562% (76.562%)\n",
      " * Prec 75.560% \n",
      "best acc: 75.990000\n",
      "Epoch: [171][0/391]\tTime 0.228 (0.228)\tData 0.188 (0.188)\tLoss 0.7967 (0.7967)\tPrec 72.656% (72.656%)\n",
      "Epoch: [171][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 0.7829 (0.6932)\tPrec 68.750% (75.340%)\n",
      "Epoch: [171][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.7001 (0.6938)\tPrec 75.781% (75.583%)\n",
      "Epoch: [171][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 0.7276 (0.6923)\tPrec 75.000% (75.491%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.174 (0.174)\tLoss 0.6154 (0.6154)\tPrec 76.562% (76.562%)\n",
      " * Prec 75.360% \n",
      "best acc: 75.990000\n",
      "Epoch: [172][0/391]\tTime 0.244 (0.244)\tData 0.198 (0.198)\tLoss 0.6853 (0.6853)\tPrec 76.562% (76.562%)\n",
      "Epoch: [172][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.7785 (0.6908)\tPrec 68.750% (75.495%)\n",
      "Epoch: [172][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.8156 (0.6926)\tPrec 71.094% (75.618%)\n",
      "Epoch: [172][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 0.6948 (0.6907)\tPrec 73.438% (75.638%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.6178 (0.6178)\tPrec 78.125% (78.125%)\n",
      " * Prec 75.550% \n",
      "best acc: 75.990000\n",
      "Epoch: [173][0/391]\tTime 0.252 (0.252)\tData 0.205 (0.205)\tLoss 0.7615 (0.7615)\tPrec 75.000% (75.000%)\n",
      "Epoch: [173][100/391]\tTime 0.065 (0.059)\tData 0.002 (0.004)\tLoss 0.6930 (0.6879)\tPrec 72.656% (76.021%)\n",
      "Epoch: [173][200/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 0.5959 (0.6818)\tPrec 81.250% (76.038%)\n",
      "Epoch: [173][300/391]\tTime 0.059 (0.059)\tData 0.002 (0.003)\tLoss 0.6669 (0.6808)\tPrec 74.219% (76.012%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.6322 (0.6322)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.000% \n",
      "best acc: 76.000000\n",
      "Epoch: [174][0/391]\tTime 0.247 (0.247)\tData 0.203 (0.203)\tLoss 0.6338 (0.6338)\tPrec 78.125% (78.125%)\n",
      "Epoch: [174][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.5937 (0.6981)\tPrec 78.125% (75.541%)\n",
      "Epoch: [174][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.6178 (0.6912)\tPrec 73.438% (75.637%)\n",
      "Epoch: [174][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.002)\tLoss 0.6422 (0.6932)\tPrec 76.562% (75.649%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.6129 (0.6129)\tPrec 75.000% (75.000%)\n",
      " * Prec 75.950% \n",
      "best acc: 76.000000\n",
      "Epoch: [175][0/391]\tTime 0.254 (0.254)\tData 0.206 (0.206)\tLoss 0.5886 (0.5886)\tPrec 81.250% (81.250%)\n",
      "Epoch: [175][100/391]\tTime 0.059 (0.059)\tData 0.002 (0.004)\tLoss 0.5911 (0.6928)\tPrec 78.906% (75.495%)\n",
      "Epoch: [175][200/391]\tTime 0.062 (0.058)\tData 0.002 (0.003)\tLoss 0.7061 (0.6813)\tPrec 78.125% (75.766%)\n",
      "Epoch: [175][300/391]\tTime 0.056 (0.058)\tData 0.003 (0.003)\tLoss 0.7884 (0.6842)\tPrec 72.656% (75.714%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.5726 (0.5726)\tPrec 78.906% (78.906%)\n",
      " * Prec 75.690% \n",
      "best acc: 76.000000\n",
      "Epoch: [176][0/391]\tTime 0.244 (0.244)\tData 0.198 (0.198)\tLoss 0.6392 (0.6392)\tPrec 81.250% (81.250%)\n",
      "Epoch: [176][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 0.7283 (0.6853)\tPrec 72.656% (75.774%)\n",
      "Epoch: [176][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 0.5964 (0.6825)\tPrec 77.344% (75.700%)\n",
      "Epoch: [176][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.7257 (0.6806)\tPrec 75.781% (75.688%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.6120 (0.6120)\tPrec 76.562% (76.562%)\n",
      " * Prec 75.850% \n",
      "best acc: 76.000000\n",
      "Epoch: [177][0/391]\tTime 0.263 (0.263)\tData 0.215 (0.215)\tLoss 0.6316 (0.6316)\tPrec 75.000% (75.000%)\n",
      "Epoch: [177][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 0.5360 (0.6933)\tPrec 82.812% (75.070%)\n",
      "Epoch: [177][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.9077 (0.6883)\tPrec 69.531% (75.412%)\n",
      "Epoch: [177][300/391]\tTime 0.062 (0.057)\tData 0.002 (0.003)\tLoss 0.8070 (0.6863)\tPrec 69.531% (75.600%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.5881 (0.5881)\tPrec 81.250% (81.250%)\n",
      " * Prec 76.010% \n",
      "best acc: 76.010000\n",
      "Epoch: [178][0/391]\tTime 0.281 (0.281)\tData 0.236 (0.236)\tLoss 0.8154 (0.8154)\tPrec 71.094% (71.094%)\n",
      "Epoch: [178][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.004)\tLoss 0.7163 (0.6651)\tPrec 71.875% (76.315%)\n",
      "Epoch: [178][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.5092 (0.6825)\tPrec 87.500% (75.882%)\n",
      "Epoch: [178][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.003)\tLoss 0.5809 (0.6832)\tPrec 78.906% (75.818%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.5793 (0.5793)\tPrec 78.125% (78.125%)\n",
      " * Prec 75.910% \n",
      "best acc: 76.010000\n",
      "Epoch: [179][0/391]\tTime 0.242 (0.242)\tData 0.200 (0.200)\tLoss 0.6317 (0.6317)\tPrec 76.562% (76.562%)\n",
      "Epoch: [179][100/391]\tTime 0.056 (0.058)\tData 0.001 (0.004)\tLoss 0.7187 (0.6795)\tPrec 73.438% (76.021%)\n",
      "Epoch: [179][200/391]\tTime 0.060 (0.058)\tData 0.002 (0.003)\tLoss 0.7500 (0.6801)\tPrec 71.875% (75.999%)\n",
      "Epoch: [179][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 0.6372 (0.6804)\tPrec 74.219% (75.945%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.5254 (0.5254)\tPrec 85.156% (85.156%)\n",
      " * Prec 76.250% \n",
      "best acc: 76.250000\n",
      "Epoch: [180][0/391]\tTime 0.300 (0.300)\tData 0.252 (0.252)\tLoss 0.5774 (0.5774)\tPrec 78.125% (78.125%)\n",
      "Epoch: [180][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.7356 (0.6872)\tPrec 74.219% (75.557%)\n",
      "Epoch: [180][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.8079 (0.6810)\tPrec 72.656% (75.882%)\n",
      "Epoch: [180][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6939 (0.6820)\tPrec 76.562% (75.919%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.5635 (0.5635)\tPrec 78.125% (78.125%)\n",
      " * Prec 75.930% \n",
      "best acc: 76.250000\n",
      "Epoch: [181][0/391]\tTime 0.251 (0.251)\tData 0.211 (0.211)\tLoss 0.6299 (0.6299)\tPrec 75.781% (75.781%)\n",
      "Epoch: [181][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 0.6252 (0.6764)\tPrec 78.125% (76.160%)\n",
      "Epoch: [181][200/391]\tTime 0.061 (0.059)\tData 0.002 (0.003)\tLoss 0.6432 (0.6771)\tPrec 78.906% (75.925%)\n",
      "Epoch: [181][300/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 0.7369 (0.6769)\tPrec 71.094% (76.041%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.6044 (0.6044)\tPrec 78.906% (78.906%)\n",
      " * Prec 76.380% \n",
      "best acc: 76.380000\n",
      "Epoch: [182][0/391]\tTime 0.267 (0.267)\tData 0.222 (0.222)\tLoss 0.7552 (0.7552)\tPrec 71.875% (71.875%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [182][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.6125 (0.6775)\tPrec 78.125% (76.253%)\n",
      "Epoch: [182][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 0.7986 (0.6765)\tPrec 71.094% (76.158%)\n",
      "Epoch: [182][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.5470 (0.6753)\tPrec 82.812% (76.319%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.5770 (0.5770)\tPrec 82.031% (82.031%)\n",
      " * Prec 76.240% \n",
      "best acc: 76.380000\n",
      "Epoch: [183][0/391]\tTime 0.262 (0.262)\tData 0.220 (0.220)\tLoss 0.5486 (0.5486)\tPrec 82.812% (82.812%)\n",
      "Epoch: [183][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.6405 (0.6693)\tPrec 78.906% (76.477%)\n",
      "Epoch: [183][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.5931 (0.6715)\tPrec 78.125% (76.356%)\n",
      "Epoch: [183][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6334 (0.6739)\tPrec 75.781% (76.235%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.5765 (0.5765)\tPrec 82.031% (82.031%)\n",
      " * Prec 76.510% \n",
      "best acc: 76.510000\n",
      "Epoch: [184][0/391]\tTime 0.271 (0.271)\tData 0.223 (0.223)\tLoss 0.5090 (0.5090)\tPrec 82.031% (82.031%)\n",
      "Epoch: [184][100/391]\tTime 0.052 (0.059)\tData 0.002 (0.004)\tLoss 0.6219 (0.6694)\tPrec 77.344% (76.462%)\n",
      "Epoch: [184][200/391]\tTime 0.059 (0.058)\tData 0.002 (0.003)\tLoss 0.7297 (0.6726)\tPrec 77.344% (76.403%)\n",
      "Epoch: [184][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.5178 (0.6701)\tPrec 82.812% (76.402%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.5841 (0.5841)\tPrec 79.688% (79.688%)\n",
      " * Prec 75.920% \n",
      "best acc: 76.510000\n",
      "Epoch: [185][0/391]\tTime 0.236 (0.236)\tData 0.188 (0.188)\tLoss 0.6205 (0.6205)\tPrec 78.906% (78.906%)\n",
      "Epoch: [185][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.7234 (0.6599)\tPrec 75.000% (76.423%)\n",
      "Epoch: [185][200/391]\tTime 0.062 (0.058)\tData 0.002 (0.003)\tLoss 0.7570 (0.6612)\tPrec 74.219% (76.644%)\n",
      "Epoch: [185][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.002)\tLoss 0.5961 (0.6632)\tPrec 78.906% (76.599%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.5907 (0.5907)\tPrec 79.688% (79.688%)\n",
      " * Prec 76.390% \n",
      "best acc: 76.510000\n",
      "Epoch: [186][0/391]\tTime 0.250 (0.250)\tData 0.208 (0.208)\tLoss 0.6957 (0.6957)\tPrec 75.781% (75.781%)\n",
      "Epoch: [186][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.5475 (0.6700)\tPrec 81.250% (76.725%)\n",
      "Epoch: [186][200/391]\tTime 0.064 (0.058)\tData 0.002 (0.003)\tLoss 0.6846 (0.6709)\tPrec 76.562% (76.477%)\n",
      "Epoch: [186][300/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.7501 (0.6675)\tPrec 75.000% (76.531%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.6248 (0.6248)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.440% \n",
      "best acc: 76.510000\n",
      "Epoch: [187][0/391]\tTime 0.271 (0.271)\tData 0.224 (0.224)\tLoss 0.6861 (0.6861)\tPrec 72.656% (72.656%)\n",
      "Epoch: [187][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.6217 (0.6711)\tPrec 75.000% (76.454%)\n",
      "Epoch: [187][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 0.6917 (0.6700)\tPrec 74.219% (76.372%)\n",
      "Epoch: [187][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.5466 (0.6676)\tPrec 81.250% (76.550%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.6168 (0.6168)\tPrec 79.688% (79.688%)\n",
      " * Prec 76.110% \n",
      "best acc: 76.510000\n",
      "Epoch: [188][0/391]\tTime 0.234 (0.234)\tData 0.187 (0.187)\tLoss 0.6525 (0.6525)\tPrec 80.469% (80.469%)\n",
      "Epoch: [188][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.5628 (0.6624)\tPrec 78.906% (76.462%)\n",
      "Epoch: [188][200/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.5226 (0.6593)\tPrec 80.469% (76.706%)\n",
      "Epoch: [188][300/391]\tTime 0.056 (0.057)\tData 0.002 (0.002)\tLoss 0.7606 (0.6628)\tPrec 72.656% (76.575%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.5830 (0.5830)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.000% \n",
      "best acc: 76.510000\n",
      "Epoch: [189][0/391]\tTime 0.256 (0.256)\tData 0.206 (0.206)\tLoss 0.7229 (0.7229)\tPrec 73.438% (73.438%)\n",
      "Epoch: [189][100/391]\tTime 0.059 (0.061)\tData 0.002 (0.004)\tLoss 0.7894 (0.6664)\tPrec 72.656% (76.454%)\n",
      "Epoch: [189][200/391]\tTime 0.053 (0.059)\tData 0.002 (0.003)\tLoss 0.4905 (0.6634)\tPrec 85.156% (76.481%)\n",
      "Epoch: [189][300/391]\tTime 0.054 (0.058)\tData 0.002 (0.002)\tLoss 0.5652 (0.6667)\tPrec 80.469% (76.386%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.182 (0.182)\tLoss 0.6053 (0.6053)\tPrec 79.688% (79.688%)\n",
      " * Prec 76.610% \n",
      "best acc: 76.610000\n",
      "Epoch: [190][0/391]\tTime 0.250 (0.250)\tData 0.210 (0.210)\tLoss 0.8976 (0.8976)\tPrec 67.969% (67.969%)\n",
      "Epoch: [190][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.7619 (0.6606)\tPrec 71.875% (76.942%)\n",
      "Epoch: [190][200/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.6339 (0.6630)\tPrec 75.781% (76.699%)\n",
      "Epoch: [190][300/391]\tTime 0.058 (0.057)\tData 0.002 (0.002)\tLoss 0.6450 (0.6630)\tPrec 75.781% (76.726%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 0.6119 (0.6119)\tPrec 78.906% (78.906%)\n",
      " * Prec 76.680% \n",
      "best acc: 76.680000\n",
      "Epoch: [191][0/391]\tTime 0.225 (0.225)\tData 0.181 (0.181)\tLoss 0.7180 (0.7180)\tPrec 72.656% (72.656%)\n",
      "Epoch: [191][100/391]\tTime 0.055 (0.059)\tData 0.002 (0.004)\tLoss 0.5327 (0.6671)\tPrec 79.688% (76.230%)\n",
      "Epoch: [191][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.7108 (0.6636)\tPrec 75.781% (76.388%)\n",
      "Epoch: [191][300/391]\tTime 0.060 (0.058)\tData 0.002 (0.002)\tLoss 0.6107 (0.6649)\tPrec 79.688% (76.485%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.6043 (0.6043)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.480% \n",
      "best acc: 76.680000\n",
      "Epoch: [192][0/391]\tTime 0.229 (0.229)\tData 0.190 (0.190)\tLoss 0.6082 (0.6082)\tPrec 77.344% (77.344%)\n",
      "Epoch: [192][100/391]\tTime 0.058 (0.059)\tData 0.002 (0.004)\tLoss 0.5481 (0.6668)\tPrec 78.906% (76.454%)\n",
      "Epoch: [192][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.5805 (0.6647)\tPrec 82.812% (76.594%)\n",
      "Epoch: [192][300/391]\tTime 0.062 (0.057)\tData 0.002 (0.002)\tLoss 0.5431 (0.6635)\tPrec 78.906% (76.552%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.6382 (0.6382)\tPrec 75.781% (75.781%)\n",
      " * Prec 76.620% \n",
      "best acc: 76.680000\n",
      "Epoch: [193][0/391]\tTime 0.299 (0.299)\tData 0.251 (0.251)\tLoss 0.6579 (0.6579)\tPrec 74.219% (74.219%)\n",
      "Epoch: [193][100/391]\tTime 0.055 (0.060)\tData 0.002 (0.004)\tLoss 0.6552 (0.6697)\tPrec 72.656% (76.586%)\n",
      "Epoch: [193][200/391]\tTime 0.058 (0.058)\tData 0.002 (0.003)\tLoss 0.7893 (0.6718)\tPrec 72.656% (76.399%)\n",
      "Epoch: [193][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.6510 (0.6658)\tPrec 77.344% (76.505%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.6134 (0.6134)\tPrec 79.688% (79.688%)\n",
      " * Prec 76.600% \n",
      "best acc: 76.680000\n",
      "Epoch: [194][0/391]\tTime 0.281 (0.281)\tData 0.233 (0.233)\tLoss 0.7362 (0.7362)\tPrec 75.000% (75.000%)\n",
      "Epoch: [194][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.7123 (0.6585)\tPrec 76.562% (76.903%)\n",
      "Epoch: [194][200/391]\tTime 0.054 (0.058)\tData 0.002 (0.003)\tLoss 0.5730 (0.6584)\tPrec 79.688% (76.664%)\n",
      "Epoch: [194][300/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.5787 (0.6577)\tPrec 79.688% (76.555%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.5875 (0.5875)\tPrec 80.469% (80.469%)\n",
      " * Prec 76.980% \n",
      "best acc: 76.980000\n",
      "Epoch: [195][0/391]\tTime 0.264 (0.264)\tData 0.211 (0.211)\tLoss 0.6865 (0.6865)\tPrec 73.438% (73.438%)\n",
      "Epoch: [195][100/391]\tTime 0.058 (0.061)\tData 0.002 (0.004)\tLoss 0.6796 (0.6544)\tPrec 80.469% (76.926%)\n",
      "Epoch: [195][200/391]\tTime 0.058 (0.059)\tData 0.002 (0.003)\tLoss 0.5247 (0.6583)\tPrec 80.469% (76.667%)\n",
      "Epoch: [195][300/391]\tTime 0.055 (0.058)\tData 0.002 (0.002)\tLoss 0.6413 (0.6579)\tPrec 78.125% (76.609%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.250 (0.250)\tLoss 0.5748 (0.5748)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.640% \n",
      "best acc: 76.980000\n",
      "Epoch: [196][0/391]\tTime 0.232 (0.232)\tData 0.187 (0.187)\tLoss 0.8316 (0.8316)\tPrec 71.875% (71.875%)\n",
      "Epoch: [196][100/391]\tTime 0.057 (0.058)\tData 0.002 (0.004)\tLoss 0.7031 (0.6605)\tPrec 75.781% (76.346%)\n",
      "Epoch: [196][200/391]\tTime 0.055 (0.057)\tData 0.002 (0.003)\tLoss 0.8624 (0.6632)\tPrec 75.781% (76.485%)\n",
      "Epoch: [196][300/391]\tTime 0.057 (0.057)\tData 0.002 (0.002)\tLoss 0.6450 (0.6625)\tPrec 79.688% (76.505%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.6306 (0.6306)\tPrec 76.562% (76.562%)\n",
      " * Prec 76.800% \n",
      "best acc: 76.980000\n",
      "Epoch: [197][0/391]\tTime 0.257 (0.257)\tData 0.215 (0.215)\tLoss 0.6282 (0.6282)\tPrec 76.562% (76.562%)\n",
      "Epoch: [197][100/391]\tTime 0.058 (0.060)\tData 0.002 (0.004)\tLoss 0.6091 (0.6686)\tPrec 76.562% (76.307%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [197][200/391]\tTime 0.058 (0.059)\tData 0.002 (0.003)\tLoss 0.6288 (0.6567)\tPrec 75.000% (76.621%)\n",
      "Epoch: [197][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.6744 (0.6532)\tPrec 78.125% (76.814%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.6193 (0.6193)\tPrec 76.562% (76.562%)\n",
      " * Prec 76.840% \n",
      "best acc: 76.980000\n",
      "Epoch: [198][0/391]\tTime 0.297 (0.297)\tData 0.248 (0.248)\tLoss 0.5786 (0.5786)\tPrec 79.688% (79.688%)\n",
      "Epoch: [198][100/391]\tTime 0.054 (0.059)\tData 0.002 (0.004)\tLoss 0.6037 (0.6472)\tPrec 78.125% (76.818%)\n",
      "Epoch: [198][200/391]\tTime 0.055 (0.058)\tData 0.002 (0.003)\tLoss 0.6246 (0.6552)\tPrec 75.781% (76.889%)\n",
      "Epoch: [198][300/391]\tTime 0.056 (0.058)\tData 0.002 (0.003)\tLoss 0.6572 (0.6610)\tPrec 77.344% (76.710%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.5410 (0.5410)\tPrec 78.906% (78.906%)\n",
      " * Prec 76.700% \n",
      "best acc: 76.980000\n",
      "Epoch: [199][0/391]\tTime 0.320 (0.320)\tData 0.272 (0.272)\tLoss 0.6200 (0.6200)\tPrec 80.469% (80.469%)\n",
      "Epoch: [199][100/391]\tTime 0.056 (0.059)\tData 0.002 (0.004)\tLoss 0.7058 (0.6561)\tPrec 78.125% (76.942%)\n",
      "Epoch: [199][200/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.8482 (0.6604)\tPrec 69.531% (76.702%)\n",
      "Epoch: [199][300/391]\tTime 0.057 (0.058)\tData 0.002 (0.003)\tLoss 0.5105 (0.6564)\tPrec 80.469% (76.786%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.6384 (0.6384)\tPrec 71.875% (71.875%)\n",
      " * Prec 77.000% \n",
      "best acc: 77.000000\n"
     ]
    }
   ],
   "source": [
    "# This cell is from the website\n",
    "\n",
    "lr = 1e-2\n",
    "\n",
    "weight_decay = 1e-4\n",
    "epochs = 200\n",
    "best_prec = 0\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# weight decay: for regularization to prevent overfitting\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "    \n",
    "fdir = 'result/'+str(model_name)\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7874589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.247 (0.247)\tData 0.206 (0.206)\tLoss 0.5886 (0.5886)\tPrec 78.125% (78.125%)\n",
      "Epoch: [0][100/391]\tTime 0.053 (0.058)\tData 0.002 (0.005)\tLoss 0.8314 (0.7575)\tPrec 69.531% (73.368%)\n",
      "Epoch: [0][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.9465 (0.7775)\tPrec 68.750% (72.520%)\n",
      "Epoch: [0][300/391]\tTime 0.056 (0.056)\tData 0.002 (0.003)\tLoss 0.6544 (0.7963)\tPrec 78.125% (71.911%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.280 (0.280)\tLoss 0.8550 (0.8550)\tPrec 69.531% (69.531%)\n",
      " * Prec 68.830% \n",
      "best acc: 68.830000\n",
      "Epoch: [1][0/391]\tTime 0.279 (0.279)\tData 0.241 (0.241)\tLoss 0.9467 (0.9467)\tPrec 68.750% (68.750%)\n",
      "Epoch: [1][100/391]\tTime 0.058 (0.057)\tData 0.002 (0.005)\tLoss 0.9046 (0.8584)\tPrec 67.969% (69.732%)\n",
      "Epoch: [1][200/391]\tTime 0.058 (0.056)\tData 0.002 (0.003)\tLoss 0.8734 (0.8604)\tPrec 68.750% (69.807%)\n",
      "Epoch: [1][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.9504 (0.8556)\tPrec 67.188% (69.970%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.7679 (0.7679)\tPrec 73.438% (73.438%)\n",
      " * Prec 69.370% \n",
      "best acc: 69.370000\n",
      "Epoch: [2][0/391]\tTime 0.299 (0.299)\tData 0.253 (0.253)\tLoss 0.7697 (0.7697)\tPrec 71.875% (71.875%)\n",
      "Epoch: [2][100/391]\tTime 0.063 (0.060)\tData 0.002 (0.004)\tLoss 0.8472 (0.8267)\tPrec 68.750% (70.800%)\n",
      "Epoch: [2][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.9082 (0.8369)\tPrec 65.625% (70.507%)\n",
      "Epoch: [2][300/391]\tTime 0.059 (0.057)\tData 0.002 (0.003)\tLoss 0.7296 (0.8381)\tPrec 70.312% (70.486%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.8397 (0.8397)\tPrec 71.094% (71.094%)\n",
      " * Prec 67.940% \n",
      "best acc: 69.370000\n",
      "Epoch: [3][0/391]\tTime 0.252 (0.252)\tData 0.202 (0.202)\tLoss 0.7429 (0.7429)\tPrec 74.219% (74.219%)\n",
      "Epoch: [3][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 0.8552 (0.8326)\tPrec 68.750% (70.653%)\n",
      "Epoch: [3][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.7966 (0.8621)\tPrec 74.219% (69.593%)\n",
      "Epoch: [3][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.002)\tLoss 0.7997 (0.8598)\tPrec 73.438% (69.705%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.7704 (0.7704)\tPrec 70.312% (70.312%)\n",
      " * Prec 69.280% \n",
      "best acc: 69.370000\n",
      "Epoch: [4][0/391]\tTime 0.257 (0.257)\tData 0.214 (0.214)\tLoss 0.8976 (0.8976)\tPrec 65.625% (65.625%)\n",
      "Epoch: [4][100/391]\tTime 0.054 (0.057)\tData 0.002 (0.004)\tLoss 0.9185 (0.8307)\tPrec 66.406% (70.591%)\n",
      "Epoch: [4][200/391]\tTime 0.060 (0.056)\tData 0.002 (0.003)\tLoss 0.6683 (0.8536)\tPrec 75.781% (70.355%)\n",
      "Epoch: [4][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.9761 (0.8641)\tPrec 67.969% (69.838%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.181 (0.181)\tLoss 0.8042 (0.8042)\tPrec 70.312% (70.312%)\n",
      " * Prec 68.960% \n",
      "best acc: 69.370000\n",
      "Epoch: [5][0/391]\tTime 0.254 (0.254)\tData 0.206 (0.206)\tLoss 0.7588 (0.7588)\tPrec 71.094% (71.094%)\n",
      "Epoch: [5][100/391]\tTime 0.052 (0.057)\tData 0.002 (0.004)\tLoss 0.8856 (0.8691)\tPrec 64.844% (68.897%)\n",
      "Epoch: [5][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.8212 (0.8661)\tPrec 71.094% (69.259%)\n",
      "Epoch: [5][300/391]\tTime 0.055 (0.055)\tData 0.002 (0.003)\tLoss 0.6726 (0.8566)\tPrec 76.562% (69.752%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.185 (0.185)\tLoss 0.8552 (0.8552)\tPrec 71.094% (71.094%)\n",
      " * Prec 69.640% \n",
      "best acc: 69.640000\n",
      "Epoch: [6][0/391]\tTime 0.243 (0.243)\tData 0.198 (0.198)\tLoss 0.7837 (0.7837)\tPrec 73.438% (73.438%)\n",
      "Epoch: [6][100/391]\tTime 0.057 (0.057)\tData 0.002 (0.004)\tLoss 0.8170 (0.8756)\tPrec 74.219% (69.601%)\n",
      "Epoch: [6][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.7996 (0.8689)\tPrec 69.531% (69.772%)\n",
      "Epoch: [6][300/391]\tTime 0.059 (0.056)\tData 0.002 (0.003)\tLoss 0.7760 (0.8740)\tPrec 69.531% (69.573%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.9127 (0.9127)\tPrec 70.312% (70.312%)\n",
      " * Prec 68.650% \n",
      "best acc: 69.640000\n",
      "Epoch: [7][0/391]\tTime 0.280 (0.280)\tData 0.235 (0.235)\tLoss 0.8436 (0.8436)\tPrec 70.312% (70.312%)\n",
      "Epoch: [7][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.9034 (0.8564)\tPrec 68.750% (69.771%)\n",
      "Epoch: [7][200/391]\tTime 0.052 (0.056)\tData 0.002 (0.003)\tLoss 0.7729 (0.8623)\tPrec 71.875% (69.605%)\n",
      "Epoch: [7][300/391]\tTime 0.059 (0.056)\tData 0.002 (0.003)\tLoss 0.8266 (0.8696)\tPrec 70.312% (69.259%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.8618 (0.8618)\tPrec 67.969% (67.969%)\n",
      " * Prec 68.120% \n",
      "best acc: 69.640000\n",
      "Epoch: [8][0/391]\tTime 0.304 (0.304)\tData 0.247 (0.247)\tLoss 0.8676 (0.8676)\tPrec 67.188% (67.188%)\n",
      "Epoch: [8][100/391]\tTime 0.052 (0.057)\tData 0.002 (0.004)\tLoss 0.7576 (0.8698)\tPrec 76.562% (69.106%)\n",
      "Epoch: [8][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 0.9657 (0.8628)\tPrec 65.625% (69.551%)\n",
      "Epoch: [8][300/391]\tTime 0.061 (0.056)\tData 0.002 (0.003)\tLoss 0.7484 (0.8644)\tPrec 78.125% (69.492%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.9523 (0.9523)\tPrec 64.844% (64.844%)\n",
      " * Prec 65.840% \n",
      "best acc: 69.640000\n",
      "Epoch: [9][0/391]\tTime 0.247 (0.247)\tData 0.199 (0.199)\tLoss 0.9858 (0.9858)\tPrec 64.844% (64.844%)\n",
      "Epoch: [9][100/391]\tTime 0.058 (0.057)\tData 0.002 (0.004)\tLoss 0.8335 (0.8735)\tPrec 68.750% (69.392%)\n",
      "Epoch: [9][200/391]\tTime 0.055 (0.056)\tData 0.004 (0.003)\tLoss 0.7868 (0.8558)\tPrec 71.875% (70.017%)\n",
      "Epoch: [9][300/391]\tTime 0.056 (0.055)\tData 0.002 (0.002)\tLoss 0.7672 (0.8584)\tPrec 72.656% (69.915%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.9224 (0.9224)\tPrec 71.094% (71.094%)\n",
      " * Prec 70.390% \n",
      "best acc: 70.390000\n",
      "Epoch: [10][0/391]\tTime 0.264 (0.264)\tData 0.220 (0.220)\tLoss 0.8492 (0.8492)\tPrec 70.312% (70.312%)\n",
      "Epoch: [10][100/391]\tTime 0.057 (0.057)\tData 0.002 (0.004)\tLoss 0.9114 (0.8489)\tPrec 67.188% (70.421%)\n",
      "Epoch: [10][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.9612 (0.8451)\tPrec 66.406% (70.281%)\n",
      "Epoch: [10][300/391]\tTime 0.052 (0.055)\tData 0.002 (0.003)\tLoss 0.6901 (0.8497)\tPrec 74.219% (70.045%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.8546 (0.8546)\tPrec 67.188% (67.188%)\n",
      " * Prec 71.200% \n",
      "best acc: 71.200000\n",
      "Epoch: [11][0/391]\tTime 0.331 (0.331)\tData 0.285 (0.285)\tLoss 0.7716 (0.7716)\tPrec 69.531% (69.531%)\n",
      "Epoch: [11][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.005)\tLoss 0.8149 (0.8556)\tPrec 70.312% (70.235%)\n",
      "Epoch: [11][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 0.9203 (0.8578)\tPrec 67.188% (70.138%)\n",
      "Epoch: [11][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.8175 (0.8643)\tPrec 72.656% (69.838%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 0.9235 (0.9235)\tPrec 66.406% (66.406%)\n",
      " * Prec 68.150% \n",
      "best acc: 71.200000\n",
      "Epoch: [12][0/391]\tTime 0.252 (0.252)\tData 0.205 (0.205)\tLoss 0.9687 (0.9687)\tPrec 65.625% (65.625%)\n",
      "Epoch: [12][100/391]\tTime 0.054 (0.057)\tData 0.002 (0.004)\tLoss 0.9593 (0.8763)\tPrec 69.531% (69.740%)\n",
      "Epoch: [12][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 1.0012 (0.8664)\tPrec 65.625% (69.877%)\n",
      "Epoch: [12][300/391]\tTime 0.055 (0.055)\tData 0.002 (0.003)\tLoss 0.9806 (0.8724)\tPrec 67.969% (69.549%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.8672 (0.8672)\tPrec 74.219% (74.219%)\n",
      " * Prec 69.090% \n",
      "best acc: 71.200000\n",
      "Epoch: [13][0/391]\tTime 0.293 (0.293)\tData 0.239 (0.239)\tLoss 1.0398 (1.0398)\tPrec 63.281% (63.281%)\n",
      "Epoch: [13][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 0.8092 (0.8687)\tPrec 72.656% (69.794%)\n",
      "Epoch: [13][200/391]\tTime 0.057 (0.056)\tData 0.002 (0.003)\tLoss 0.8006 (0.8624)\tPrec 71.875% (70.141%)\n",
      "Epoch: [13][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 0.7782 (0.8488)\tPrec 73.438% (70.497%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 0.8734 (0.8734)\tPrec 71.094% (71.094%)\n",
      " * Prec 71.530% \n",
      "best acc: 71.530000\n",
      "Epoch: [14][0/391]\tTime 0.300 (0.300)\tData 0.262 (0.262)\tLoss 0.8178 (0.8178)\tPrec 73.438% (73.438%)\n",
      "Epoch: [14][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.004)\tLoss 0.8953 (0.8288)\tPrec 68.750% (70.985%)\n",
      "Epoch: [14][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.7725 (0.8241)\tPrec 76.562% (71.047%)\n",
      "Epoch: [14][300/391]\tTime 0.058 (0.056)\tData 0.002 (0.003)\tLoss 0.6711 (0.8208)\tPrec 80.469% (71.185%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.185 (0.185)\tLoss 0.8970 (0.8970)\tPrec 71.094% (71.094%)\n",
      " * Prec 69.930% \n",
      "best acc: 71.530000\n",
      "Epoch: [15][0/391]\tTime 0.266 (0.266)\tData 0.225 (0.225)\tLoss 1.0322 (1.0322)\tPrec 66.406% (66.406%)\n",
      "Epoch: [15][100/391]\tTime 0.056 (0.058)\tData 0.002 (0.004)\tLoss 0.7054 (0.8317)\tPrec 80.469% (71.040%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [15][200/391]\tTime 0.058 (0.056)\tData 0.002 (0.003)\tLoss 0.7487 (0.8193)\tPrec 74.219% (71.451%)\n",
      "Epoch: [15][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 0.8942 (0.8257)\tPrec 67.188% (71.340%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.8383 (0.8383)\tPrec 67.969% (67.969%)\n",
      " * Prec 70.570% \n",
      "best acc: 71.530000\n",
      "Epoch: [16][0/391]\tTime 0.263 (0.263)\tData 0.215 (0.215)\tLoss 0.9081 (0.9081)\tPrec 67.969% (67.969%)\n",
      "Epoch: [16][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.004)\tLoss 0.7558 (0.8184)\tPrec 73.438% (71.279%)\n",
      "Epoch: [16][200/391]\tTime 0.058 (0.056)\tData 0.002 (0.003)\tLoss 0.8654 (0.8184)\tPrec 67.969% (71.591%)\n",
      "Epoch: [16][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.7577 (0.8104)\tPrec 71.094% (71.789%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.229 (0.229)\tLoss 0.8590 (0.8590)\tPrec 71.094% (71.094%)\n",
      " * Prec 69.840% \n",
      "best acc: 71.530000\n",
      "Epoch: [17][0/391]\tTime 0.239 (0.239)\tData 0.190 (0.190)\tLoss 0.7978 (0.7978)\tPrec 69.531% (69.531%)\n",
      "Epoch: [17][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.004)\tLoss 0.6299 (0.8184)\tPrec 81.250% (71.403%)\n",
      "Epoch: [17][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.6795 (0.8182)\tPrec 75.781% (71.377%)\n",
      "Epoch: [17][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.002)\tLoss 0.8011 (0.8158)\tPrec 71.094% (71.327%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.7877 (0.7877)\tPrec 73.438% (73.438%)\n",
      " * Prec 70.380% \n",
      "best acc: 71.530000\n",
      "Epoch: [18][0/391]\tTime 0.280 (0.280)\tData 0.236 (0.236)\tLoss 0.7550 (0.7550)\tPrec 74.219% (74.219%)\n",
      "Epoch: [18][100/391]\tTime 0.059 (0.057)\tData 0.002 (0.004)\tLoss 0.9576 (0.8275)\tPrec 67.188% (70.939%)\n",
      "Epoch: [18][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.7504 (0.8400)\tPrec 75.000% (70.421%)\n",
      "Epoch: [18][300/391]\tTime 0.057 (0.056)\tData 0.002 (0.003)\tLoss 0.8717 (0.8383)\tPrec 63.281% (70.510%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.8001 (0.8001)\tPrec 71.094% (71.094%)\n",
      " * Prec 70.440% \n",
      "best acc: 71.530000\n",
      "Epoch: [19][0/391]\tTime 0.258 (0.258)\tData 0.215 (0.215)\tLoss 0.8579 (0.8579)\tPrec 67.969% (67.969%)\n",
      "Epoch: [19][100/391]\tTime 0.050 (0.058)\tData 0.002 (0.004)\tLoss 0.7915 (0.8146)\tPrec 70.312% (71.287%)\n",
      "Epoch: [19][200/391]\tTime 0.054 (0.057)\tData 0.002 (0.003)\tLoss 0.8088 (0.8236)\tPrec 74.219% (70.880%)\n",
      "Epoch: [19][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.002)\tLoss 0.6427 (0.8312)\tPrec 76.562% (70.733%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.7286 (0.7286)\tPrec 75.000% (75.000%)\n",
      " * Prec 71.320% \n",
      "best acc: 71.530000\n",
      "Epoch: [20][0/391]\tTime 0.266 (0.266)\tData 0.219 (0.219)\tLoss 0.7210 (0.7210)\tPrec 73.438% (73.438%)\n",
      "Epoch: [20][100/391]\tTime 0.062 (0.057)\tData 0.002 (0.004)\tLoss 0.7381 (0.8115)\tPrec 75.781% (71.813%)\n",
      "Epoch: [20][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.7868 (0.8258)\tPrec 74.219% (71.195%)\n",
      "Epoch: [20][300/391]\tTime 0.055 (0.056)\tData 0.004 (0.003)\tLoss 0.8695 (0.8199)\tPrec 63.281% (71.434%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.223 (0.223)\tLoss 0.7409 (0.7409)\tPrec 75.781% (75.781%)\n",
      " * Prec 71.600% \n",
      "best acc: 71.600000\n",
      "Epoch: [21][0/391]\tTime 0.286 (0.286)\tData 0.236 (0.236)\tLoss 0.8170 (0.8170)\tPrec 64.844% (64.844%)\n",
      "Epoch: [21][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.004)\tLoss 0.8948 (0.8281)\tPrec 71.094% (71.218%)\n",
      "Epoch: [21][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.8291 (0.8198)\tPrec 70.312% (71.514%)\n",
      "Epoch: [21][300/391]\tTime 0.055 (0.056)\tData 0.003 (0.003)\tLoss 0.9245 (0.8210)\tPrec 64.844% (71.558%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.243 (0.243)\tLoss 0.8148 (0.8148)\tPrec 71.094% (71.094%)\n",
      " * Prec 71.480% \n",
      "best acc: 71.600000\n",
      "Epoch: [22][0/391]\tTime 0.276 (0.276)\tData 0.229 (0.229)\tLoss 0.8465 (0.8465)\tPrec 70.312% (70.312%)\n",
      "Epoch: [22][100/391]\tTime 0.057 (0.059)\tData 0.003 (0.004)\tLoss 0.7657 (0.8018)\tPrec 76.562% (72.177%)\n",
      "Epoch: [22][200/391]\tTime 0.057 (0.057)\tData 0.002 (0.003)\tLoss 0.8674 (0.8047)\tPrec 71.094% (72.023%)\n",
      "Epoch: [22][300/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.6519 (0.8097)\tPrec 74.219% (71.833%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.218 (0.218)\tLoss 0.9171 (0.9171)\tPrec 68.750% (68.750%)\n",
      " * Prec 70.080% \n",
      "best acc: 71.600000\n",
      "Epoch: [23][0/391]\tTime 0.268 (0.268)\tData 0.223 (0.223)\tLoss 0.9144 (0.9144)\tPrec 73.438% (73.438%)\n",
      "Epoch: [23][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.004)\tLoss 0.7236 (0.8547)\tPrec 75.000% (70.429%)\n",
      "Epoch: [23][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.7673 (0.8459)\tPrec 72.656% (70.693%)\n",
      "Epoch: [23][300/391]\tTime 0.054 (0.055)\tData 0.002 (0.003)\tLoss 0.6841 (0.8363)\tPrec 76.562% (71.104%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 1.0401 (1.0401)\tPrec 66.406% (66.406%)\n",
      " * Prec 67.690% \n",
      "best acc: 71.600000\n",
      "Epoch: [24][0/391]\tTime 0.258 (0.258)\tData 0.210 (0.210)\tLoss 0.8491 (0.8491)\tPrec 73.438% (73.438%)\n",
      "Epoch: [24][100/391]\tTime 0.054 (0.057)\tData 0.002 (0.004)\tLoss 0.7002 (0.8152)\tPrec 76.562% (71.666%)\n",
      "Epoch: [24][200/391]\tTime 0.057 (0.056)\tData 0.002 (0.003)\tLoss 0.6844 (0.8153)\tPrec 78.906% (71.731%)\n",
      "Epoch: [24][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.8509 (0.8107)\tPrec 67.969% (71.888%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.184 (0.184)\tLoss 0.8392 (0.8392)\tPrec 71.094% (71.094%)\n",
      " * Prec 70.170% \n",
      "best acc: 71.600000\n",
      "Epoch: [25][0/391]\tTime 0.266 (0.266)\tData 0.221 (0.221)\tLoss 0.8528 (0.8528)\tPrec 70.312% (70.312%)\n",
      "Epoch: [25][100/391]\tTime 0.056 (0.057)\tData 0.002 (0.004)\tLoss 0.7871 (0.8427)\tPrec 69.531% (70.421%)\n",
      "Epoch: [25][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 0.7422 (0.8387)\tPrec 71.875% (70.410%)\n",
      "Epoch: [25][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.7508 (0.8472)\tPrec 74.219% (70.232%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.8365 (0.8365)\tPrec 70.312% (70.312%)\n",
      " * Prec 70.600% \n",
      "best acc: 71.600000\n",
      "Epoch: [26][0/391]\tTime 0.281 (0.281)\tData 0.235 (0.235)\tLoss 0.8952 (0.8952)\tPrec 65.625% (65.625%)\n",
      "Epoch: [26][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.9155 (0.8266)\tPrec 70.312% (70.854%)\n",
      "Epoch: [26][200/391]\tTime 0.054 (0.056)\tData 0.002 (0.003)\tLoss 0.8931 (0.8252)\tPrec 63.281% (70.896%)\n",
      "Epoch: [26][300/391]\tTime 0.057 (0.055)\tData 0.002 (0.003)\tLoss 0.6307 (0.8193)\tPrec 77.344% (71.369%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.8870 (0.8870)\tPrec 68.750% (68.750%)\n",
      " * Prec 71.020% \n",
      "best acc: 71.600000\n",
      "Epoch: [27][0/391]\tTime 0.275 (0.275)\tData 0.229 (0.229)\tLoss 0.7626 (0.7626)\tPrec 75.781% (75.781%)\n",
      "Epoch: [27][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.7712 (0.8225)\tPrec 75.000% (71.705%)\n",
      "Epoch: [27][200/391]\tTime 0.059 (0.056)\tData 0.002 (0.003)\tLoss 0.8689 (0.8195)\tPrec 68.750% (71.650%)\n",
      "Epoch: [27][300/391]\tTime 0.059 (0.055)\tData 0.002 (0.003)\tLoss 0.9228 (0.8197)\tPrec 67.188% (71.566%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.8186 (0.8186)\tPrec 69.531% (69.531%)\n",
      " * Prec 70.670% \n",
      "best acc: 71.600000\n",
      "Epoch: [28][0/391]\tTime 0.251 (0.251)\tData 0.209 (0.209)\tLoss 0.7324 (0.7324)\tPrec 78.125% (78.125%)\n",
      "Epoch: [28][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.004)\tLoss 0.8498 (0.8121)\tPrec 71.875% (71.658%)\n",
      "Epoch: [28][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.7811 (0.8230)\tPrec 70.312% (71.156%)\n",
      "Epoch: [28][300/391]\tTime 0.055 (0.055)\tData 0.002 (0.002)\tLoss 0.8959 (0.8165)\tPrec 67.969% (71.333%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.9388 (0.9388)\tPrec 71.094% (71.094%)\n",
      " * Prec 68.830% \n",
      "best acc: 71.600000\n",
      "Epoch: [29][0/391]\tTime 0.326 (0.326)\tData 0.279 (0.279)\tLoss 0.9276 (0.9276)\tPrec 71.094% (71.094%)\n",
      "Epoch: [29][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.005)\tLoss 0.7006 (0.8251)\tPrec 72.656% (71.086%)\n",
      "Epoch: [29][200/391]\tTime 0.053 (0.057)\tData 0.002 (0.003)\tLoss 0.8741 (0.8180)\tPrec 67.188% (71.385%)\n",
      "Epoch: [29][300/391]\tTime 0.052 (0.056)\tData 0.002 (0.003)\tLoss 0.9028 (0.8399)\tPrec 67.188% (70.930%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.9370 (0.9370)\tPrec 65.625% (65.625%)\n",
      " * Prec 68.770% \n",
      "best acc: 71.600000\n",
      "Epoch: [30][0/391]\tTime 0.264 (0.264)\tData 0.219 (0.219)\tLoss 0.8289 (0.8289)\tPrec 71.094% (71.094%)\n",
      "Epoch: [30][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.8340 (0.8906)\tPrec 75.000% (69.779%)\n",
      "Epoch: [30][200/391]\tTime 0.051 (0.056)\tData 0.002 (0.003)\tLoss 0.8593 (0.8733)\tPrec 71.094% (70.274%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][300/391]\tTime 0.057 (0.056)\tData 0.002 (0.003)\tLoss 0.7721 (0.8605)\tPrec 73.438% (70.775%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 1.0215 (1.0215)\tPrec 63.281% (63.281%)\n",
      " * Prec 66.030% \n",
      "best acc: 71.600000\n",
      "Epoch: [31][0/391]\tTime 0.256 (0.256)\tData 0.214 (0.214)\tLoss 0.7942 (0.7942)\tPrec 75.000% (75.000%)\n",
      "Epoch: [31][100/391]\tTime 0.054 (0.057)\tData 0.002 (0.004)\tLoss 0.7934 (0.8727)\tPrec 70.312% (69.377%)\n",
      "Epoch: [31][200/391]\tTime 0.051 (0.056)\tData 0.002 (0.003)\tLoss 0.7520 (0.8763)\tPrec 71.094% (69.209%)\n",
      "Epoch: [31][300/391]\tTime 0.055 (0.055)\tData 0.002 (0.003)\tLoss 0.9515 (0.8705)\tPrec 64.062% (69.632%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.8425 (0.8425)\tPrec 67.969% (67.969%)\n",
      " * Prec 69.610% \n",
      "best acc: 71.600000\n",
      "Epoch: [32][0/391]\tTime 0.246 (0.246)\tData 0.200 (0.200)\tLoss 0.7954 (0.7954)\tPrec 71.875% (71.875%)\n",
      "Epoch: [32][100/391]\tTime 0.054 (0.058)\tData 0.002 (0.004)\tLoss 0.8681 (0.8236)\tPrec 71.875% (71.635%)\n",
      "Epoch: [32][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.8169 (0.8280)\tPrec 73.438% (71.304%)\n",
      "Epoch: [32][300/391]\tTime 0.054 (0.056)\tData 0.002 (0.002)\tLoss 0.8872 (0.8258)\tPrec 64.844% (71.377%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.7805 (0.7805)\tPrec 71.094% (71.094%)\n",
      " * Prec 71.840% \n",
      "best acc: 71.840000\n",
      "Epoch: [33][0/391]\tTime 0.313 (0.313)\tData 0.263 (0.263)\tLoss 0.8430 (0.8430)\tPrec 68.750% (68.750%)\n",
      "Epoch: [33][100/391]\tTime 0.055 (0.058)\tData 0.002 (0.004)\tLoss 0.7025 (0.7975)\tPrec 77.344% (72.277%)\n",
      "Epoch: [33][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.7500 (0.8171)\tPrec 72.656% (71.657%)\n",
      "Epoch: [33][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.8172 (0.8287)\tPrec 73.438% (71.179%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.228 (0.228)\tLoss 0.8108 (0.8108)\tPrec 71.875% (71.875%)\n",
      " * Prec 71.060% \n",
      "best acc: 71.840000\n",
      "Epoch: [34][0/391]\tTime 0.248 (0.248)\tData 0.201 (0.201)\tLoss 0.8414 (0.8414)\tPrec 75.000% (75.000%)\n",
      "Epoch: [34][100/391]\tTime 0.052 (0.057)\tData 0.002 (0.004)\tLoss 0.7729 (0.8333)\tPrec 75.000% (70.769%)\n",
      "Epoch: [34][200/391]\tTime 0.058 (0.056)\tData 0.002 (0.003)\tLoss 0.7752 (0.8333)\tPrec 70.312% (70.927%)\n",
      "Epoch: [34][300/391]\tTime 0.058 (0.055)\tData 0.002 (0.002)\tLoss 0.6166 (0.8372)\tPrec 75.000% (70.749%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.9049 (0.9049)\tPrec 65.625% (65.625%)\n",
      " * Prec 71.570% \n",
      "best acc: 71.840000\n",
      "Epoch: [35][0/391]\tTime 0.262 (0.262)\tData 0.217 (0.217)\tLoss 0.9024 (0.9024)\tPrec 70.312% (70.312%)\n",
      "Epoch: [35][100/391]\tTime 0.056 (0.057)\tData 0.002 (0.004)\tLoss 0.7717 (0.8233)\tPrec 73.438% (71.519%)\n",
      "Epoch: [35][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.9659 (0.8088)\tPrec 64.062% (71.933%)\n",
      "Epoch: [35][300/391]\tTime 0.055 (0.055)\tData 0.002 (0.003)\tLoss 0.8307 (0.8106)\tPrec 71.094% (71.857%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.8538 (0.8538)\tPrec 69.531% (69.531%)\n",
      " * Prec 71.440% \n",
      "best acc: 71.840000\n",
      "Epoch: [36][0/391]\tTime 0.274 (0.274)\tData 0.227 (0.227)\tLoss 0.7561 (0.7561)\tPrec 76.562% (76.562%)\n",
      "Epoch: [36][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 1.0433 (0.7839)\tPrec 68.750% (72.873%)\n",
      "Epoch: [36][200/391]\tTime 0.058 (0.057)\tData 0.002 (0.003)\tLoss 0.8876 (0.7903)\tPrec 66.406% (72.633%)\n",
      "Epoch: [36][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.8297 (0.8152)\tPrec 74.219% (71.784%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.8199 (0.8199)\tPrec 69.531% (69.531%)\n",
      " * Prec 71.870% \n",
      "best acc: 71.870000\n",
      "Epoch: [37][0/391]\tTime 0.267 (0.267)\tData 0.217 (0.217)\tLoss 0.8021 (0.8021)\tPrec 70.312% (70.312%)\n",
      "Epoch: [37][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 1.0671 (0.8046)\tPrec 60.156% (72.053%)\n",
      "Epoch: [37][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.7711 (0.8075)\tPrec 71.875% (71.793%)\n",
      "Epoch: [37][300/391]\tTime 0.055 (0.055)\tData 0.002 (0.002)\tLoss 0.8249 (0.8104)\tPrec 74.219% (71.810%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.210 (0.210)\tLoss 0.8782 (0.8782)\tPrec 71.094% (71.094%)\n",
      " * Prec 71.440% \n",
      "best acc: 71.870000\n",
      "Epoch: [38][0/391]\tTime 0.264 (0.264)\tData 0.223 (0.223)\tLoss 0.8175 (0.8175)\tPrec 70.312% (70.312%)\n",
      "Epoch: [38][100/391]\tTime 0.057 (0.059)\tData 0.002 (0.004)\tLoss 0.9103 (0.8366)\tPrec 64.844% (70.591%)\n",
      "Epoch: [38][200/391]\tTime 0.055 (0.057)\tData 0.005 (0.003)\tLoss 0.9114 (0.8306)\tPrec 70.312% (71.086%)\n",
      "Epoch: [38][300/391]\tTime 0.052 (0.056)\tData 0.002 (0.003)\tLoss 0.8031 (0.8268)\tPrec 72.656% (71.208%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 0.7494 (0.7494)\tPrec 72.656% (72.656%)\n",
      " * Prec 71.060% \n",
      "best acc: 71.870000\n",
      "Epoch: [39][0/391]\tTime 0.234 (0.234)\tData 0.187 (0.187)\tLoss 0.8398 (0.8398)\tPrec 67.969% (67.969%)\n",
      "Epoch: [39][100/391]\tTime 0.055 (0.056)\tData 0.002 (0.004)\tLoss 0.7172 (0.8206)\tPrec 72.656% (71.303%)\n",
      "Epoch: [39][200/391]\tTime 0.052 (0.056)\tData 0.002 (0.003)\tLoss 0.7211 (0.8099)\tPrec 72.656% (71.871%)\n",
      "Epoch: [39][300/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 0.7154 (0.8126)\tPrec 75.000% (71.670%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.8759 (0.8759)\tPrec 68.750% (68.750%)\n",
      " * Prec 71.120% \n",
      "best acc: 71.870000\n",
      "Epoch: [40][0/391]\tTime 0.238 (0.238)\tData 0.196 (0.196)\tLoss 0.7398 (0.7398)\tPrec 74.219% (74.219%)\n",
      "Epoch: [40][100/391]\tTime 0.055 (0.057)\tData 0.002 (0.004)\tLoss 0.9276 (0.8406)\tPrec 67.969% (70.730%)\n",
      "Epoch: [40][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 1.0191 (0.8489)\tPrec 67.188% (70.503%)\n",
      "Epoch: [40][300/391]\tTime 0.058 (0.056)\tData 0.002 (0.003)\tLoss 1.0179 (0.8634)\tPrec 63.281% (70.123%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.8034 (0.8034)\tPrec 74.219% (74.219%)\n",
      " * Prec 70.700% \n",
      "best acc: 71.870000\n",
      "Epoch: [41][0/391]\tTime 0.273 (0.273)\tData 0.222 (0.222)\tLoss 1.0951 (1.0951)\tPrec 57.812% (57.812%)\n",
      "Epoch: [41][100/391]\tTime 0.056 (0.057)\tData 0.002 (0.004)\tLoss 0.8671 (0.8305)\tPrec 69.531% (71.063%)\n",
      "Epoch: [41][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 1.0879 (0.8429)\tPrec 60.938% (70.728%)\n",
      "Epoch: [41][300/391]\tTime 0.051 (0.055)\tData 0.002 (0.003)\tLoss 0.7564 (0.8379)\tPrec 72.656% (70.855%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.180 (0.180)\tLoss 0.8329 (0.8329)\tPrec 70.312% (70.312%)\n",
      " * Prec 70.310% \n",
      "best acc: 71.870000\n",
      "Epoch: [42][0/391]\tTime 0.254 (0.254)\tData 0.214 (0.214)\tLoss 0.8252 (0.8252)\tPrec 71.094% (71.094%)\n",
      "Epoch: [42][100/391]\tTime 0.053 (0.057)\tData 0.002 (0.004)\tLoss 0.9085 (0.8603)\tPrec 71.094% (70.080%)\n",
      "Epoch: [42][200/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 1.0464 (0.8417)\tPrec 71.094% (70.771%)\n",
      "Epoch: [42][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.003)\tLoss 0.8219 (0.8461)\tPrec 75.781% (70.567%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 0.8432 (0.8432)\tPrec 69.531% (69.531%)\n",
      " * Prec 69.540% \n",
      "best acc: 71.870000\n",
      "Epoch: [43][0/391]\tTime 0.259 (0.259)\tData 0.212 (0.212)\tLoss 0.8663 (0.8663)\tPrec 66.406% (66.406%)\n",
      "Epoch: [43][100/391]\tTime 0.057 (0.057)\tData 0.002 (0.004)\tLoss 0.8238 (0.8603)\tPrec 70.312% (70.367%)\n",
      "Epoch: [43][200/391]\tTime 0.053 (0.056)\tData 0.002 (0.003)\tLoss 0.9929 (0.8497)\tPrec 67.188% (70.631%)\n",
      "Epoch: [43][300/391]\tTime 0.055 (0.056)\tData 0.002 (0.002)\tLoss 0.8119 (0.8418)\tPrec 68.750% (71.000%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_601/3278636838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0madjust_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m# evaluate on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_601/1626311515.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainloader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# compute gradient and do SGD step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This cell is from the website\n",
    "PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "lr = 1e-2\n",
    "\n",
    "weight_decay = 1e-4\n",
    "epochs = 100\n",
    "best_prec = 0\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# weight decay: for regularization to prevent overfitting\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "    \n",
    "fdir = 'result/'+str(model_name)\n",
    "\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 7187/10000 (72%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "driving-tanzania",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked QuantConv2d(\n",
      "  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "7 -th layer prehooked QuantConv2d(\n",
      "  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "12 -th layer prehooked QuantConv2d(\n",
      "  64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "16 -th layer prehooked QuantConv2d(\n",
      "  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "21 -th layer prehooked QuantConv2d(\n",
      "  128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "25 -th layer prehooked QuantConv2d(\n",
      "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "29 -th layer prehooked QuantConv2d(\n",
      "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "34 -th layer prehooked QuantConv2d(\n",
      "  256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "37 -th layer prehooked QuantConv2d(\n",
      "  8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "40 -th layer prehooked QuantConv2d(\n",
      "  8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "45 -th layer prehooked QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "49 -th layer prehooked QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "53 -th layer prehooked QuantConv2d(\n",
      "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Send an image and use prehook to grab the inputs of all the QuantConv2d layers\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "i = 0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\",str(layer))\n",
    "        layer.register_forward_pre_hook(save_output)             \n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "model.cuda()\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "furnished-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -1.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -1.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000],\n",
      "          [ 1.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-1.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -1.0000],\n",
      "          [ 0.0000, -0.0000, -1.0000],\n",
      "          [-0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -1.0000, -1.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 4.0000,  7.0000,  3.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.0000, -0.0000, -1.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-1.0000, -0.0000, -1.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  1.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000],\n",
      "          [ 0.0000, -3.0000, -1.0000],\n",
      "          [ 1.0000,  1.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  1.0000],\n",
      "          [-0.0000, -1.0000,  0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  1.0000],\n",
      "          [-1.0000, -1.0000,  1.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [-1.0000, -1.0000, -1.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  1.0000,  1.0000],\n",
      "          [ 4.0000,  7.0000, -1.0000],\n",
      "          [-1.0000,  0.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000, -0.0000,  0.0000],\n",
      "          [-1.0000,  0.0000,  0.0000],\n",
      "          [-1.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -1.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -1.0000, -0.0000],\n",
      "          [-2.0000, -7.0000, -6.0000],\n",
      "          [-0.0000, -0.0000, -2.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000],\n",
      "          [ 1.0000,  2.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [ 1.0000,  2.0000,  0.0000],\n",
      "          [-0.0000,  1.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -1.0000, -1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -1.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -1.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [ 1.0000,  1.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-1.0000, -1.0000, -0.0000],\n",
      "          [ 2.0000,  2.0000,  1.0000],\n",
      "          [ 0.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -1.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.0000, -0.0000,  0.0000],\n",
      "          [ 1.0000,  3.0000,  0.0000],\n",
      "          [ 2.0000,  1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -0.0000,  0.0000],\n",
      "          [-1.0000, -0.0000, -1.0000],\n",
      "          [-0.0000, -1.0000, -1.0000]],\n",
      "\n",
      "         [[-1.0000, -0.0000, -0.0000],\n",
      "          [-1.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -1.0000, -2.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  1.0000,  0.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -1.0000],\n",
      "          [-0.0000, -0.0000, -1.0000],\n",
      "          [-0.0000, -1.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  4.0000, -0.0000],\n",
      "          [ 2.0000,  7.0000,  1.0000],\n",
      "          [ 0.0000, -0.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  1.0000,  0.0000],\n",
      "          [ 3.0000,  7.0000,  4.0000],\n",
      "          [ 0.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -1.0000, -1.0000],\n",
      "          [ 0.0000,  1.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0000],\n",
      "          [-1.0000, -0.0000,  0.0000],\n",
      "          [-1.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000,  0.0000],\n",
      "          [-1.0000, -1.0000,  1.0000],\n",
      "          [-1.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -1.0000],\n",
      "          [ 0.0000,  1.0000,  0.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -0.0000],\n",
      "          [-0.0000, -1.0000, -0.0000],\n",
      "          [-0.0000, -1.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -1.0000, -1.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000],\n",
      "          [ 3.0000,  5.0000,  2.0000],\n",
      "          [-0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "         [[-0.0000, -1.0000, -0.0000],\n",
      "          [-3.0000, -6.0000, -2.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  1.0000, -0.0000],\n",
      "          [-1.0000, -1.0000,  0.0000],\n",
      "          [ 1.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-1.0000, -0.0000, -0.0000],\n",
      "          [-1.0000,  0.0000,  0.0000],\n",
      "          [-1.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-1.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  1.0000],\n",
      "          [-1.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000,  0.0000,  1.0000]],\n",
      "\n",
      "         [[-1.0000, -0.0000, -0.0000],\n",
      "          [-0.0000, -1.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -1.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -1.0000],\n",
      "          [ 1.0000,  0.0000,  1.0000],\n",
      "          [-0.0000, -0.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000, -1.0000, -0.0000],\n",
      "          [-1.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000, -0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-1.0000, -1.0000, -0.0000],\n",
      "          [-2.0000, -5.0000, -7.0000],\n",
      "          [ 0.0000,  0.0000, -1.0000]],\n",
      "\n",
      "         [[ 1.0000, -1.0000,  2.0000],\n",
      "          [ 1.0000, -0.0000,  3.0000],\n",
      "          [-0.0000, -0.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000, -1.0000,  1.0000],\n",
      "          [ 2.0000, -0.0000,  4.0000],\n",
      "          [ 0.0000, -0.0000,  1.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -1.0000],\n",
      "          [-0.0000, -1.0000, -1.0000],\n",
      "          [-0.0000, -1.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000],\n",
      "          [ 2.0000,  1.0000, -0.0000],\n",
      "          [-0.0000, -1.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[-0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 1.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  0.0000],\n",
      "          [ 1.0000,  7.0000,  2.0000],\n",
      "          [-0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000,  0.0000],\n",
      "          [-0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -1.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-1.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  1.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[-0.0000, -1.0000, -0.0000],\n",
      "          [-1.0000, -1.0000, -1.0000],\n",
      "          [-1.0000, -0.0000, -1.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0000,  0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000],\n",
      "          [ 0.0000,  0.0000, -0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#print(model.features[26].weight)\n",
    "w_bits = 4\n",
    "weight_q = model.features[26].weight_q # quantized value is stored during\n",
    "w_alpha = model.features[26].weight_quant.wgt_alpha\n",
    "w_delta = w_alpha/(2**(w_bits-1)-1)\n",
    "weight_int = weight_q/w_delta\n",
    "print(weight_int) # you should see clean integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dated-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [15.0000, 15.0000, 15.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000, 15.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, 15.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 12.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000, 15.0000, 15.0000, 15.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [15.0000, 15.0000, 15.0000, 15.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000]],\n",
      "\n",
      "         [[15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000, 15.0000, 15.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "         [[15.0000, 15.0000, 15.0000,  0.0000],\n",
      "          [15.0000, 15.0000, 15.0000, 15.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "          [ 0.0000,  0.0000,  0.0000,  0.0000]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x_bit = 4\n",
    "x = save_output.outputs[8][0] # input of the 2nd conv layer\n",
    "x_alpha = model.features[26].act_alpha\n",
    "x_delta = x_alpha/(2**x_bit-1) # resolution\n",
    "act_quant_fn = act_quantization(x_bit) # define the quantization function\n",
    "x_q = act_quant_fn(x, x_alpha) # create the quantized value for x\n",
    "x_int = x_q/x_delta\n",
    "print(x_int) # you should see clean integer numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "textile-cancer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 5.3364e+00,  8.8939e+00,  1.1562e+01,  1.1562e+01],\n",
      "          [-8.8939e-01,  3.5576e+00,  8.0045e+00,  8.8939e+00],\n",
      "          [-4.4470e+00, -2.6682e+00,  3.3797e+00,  7.1152e+00],\n",
      "          [-4.4470e+00, -4.4470e+00, -8.8939e-01,  4.4470e+00]],\n",
      "\n",
      "         [[ 1.7788e+00,  4.4470e+00,  5.5142e+00,  7.1152e+00],\n",
      "          [ 1.7788e+00,  8.8939e-01,  7.2930e+00,  7.6488e+00],\n",
      "          [ 0.0000e+00,  8.8939e-01,  7.8267e+00,  1.0495e+01],\n",
      "          [-8.8939e-01,  0.0000e+00, -1.1309e-07, -3.5576e+00]],\n",
      "\n",
      "         [[-7.1152e+00, -8.8939e+00, -8.8939e-01,  5.1585e+00],\n",
      "          [-1.0673e+01, -1.0673e+01, -1.7788e+00,  6.2258e+00],\n",
      "          [-1.0673e+01, -1.1562e+01, -5.3364e+00,  4.4470e+00],\n",
      "          [-8.8939e+00, -9.7833e+00, -9.7833e+00, -2.6682e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.1152e+00,  1.7788e+00, -3.3797e+00, -7.1152e+00],\n",
      "          [ 5.3364e+00, -1.7788e+00, -6.4036e+00, -9.7833e+00],\n",
      "          [ 8.0045e+00,  5.3364e+00,  5.5142e+00,  2.6682e+00],\n",
      "          [ 7.1152e+00,  5.3364e+00,  3.5576e+00, -1.7788e+00]],\n",
      "\n",
      "         [[-3.5576e+00, -1.7788e+00,  4.4470e+00,  1.9567e+00],\n",
      "          [-4.4470e+00, -2.6682e+00,  5.3364e+00,  2.4903e+00],\n",
      "          [-4.4470e+00, -2.6682e+00,  5.3364e+00,  2.6682e+00],\n",
      "          [-5.3364e+00, -3.5576e+00, -3.5576e+00, -4.4470e+00]],\n",
      "\n",
      "         [[ 1.7788e+00,  8.8939e+00,  9.7833e+00,  8.8939e+00],\n",
      "          [ 8.8939e-01,  8.8939e+00,  1.0673e+01,  9.7833e+00],\n",
      "          [-8.8939e-01,  8.8939e-01,  1.7788e+00,  2.6682e+00],\n",
      "          [-8.8939e-01, -8.8939e-01, -8.8939e-01, -1.1309e-07]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2258e+00,  1.0673e+01,  1.1562e+01,  1.1562e+01],\n",
      "          [-3.5576e+00, -8.8939e-01,  5.3364e+00,  9.7833e+00],\n",
      "          [-3.5576e+00, -4.4470e+00, -8.8939e-01,  5.3364e+00],\n",
      "          [-3.5576e+00, -3.5576e+00, -2.6682e+00, -8.8939e-01]],\n",
      "\n",
      "         [[-1.7788e+00,  3.5576e+00,  5.3364e+00,  6.2258e+00],\n",
      "          [-8.8939e-01,  7.1152e+00,  9.7833e+00,  7.1152e+00],\n",
      "          [ 8.8939e-01,  3.5576e+00,  8.0045e+00,  8.0045e+00],\n",
      "          [-1.7788e+00, -8.8939e-01,  1.7788e+00, -1.7788e+00]],\n",
      "\n",
      "         [[ 5.3364e+00,  8.8939e+00,  9.7833e+00,  9.7833e+00],\n",
      "          [-3.5576e+00,  3.5576e+00,  7.1152e+00,  8.8939e+00],\n",
      "          [-4.4470e+00,  2.6682e+00,  5.3364e+00,  6.2258e+00],\n",
      "          [-8.8939e+00, -3.5576e+00,  2.6682e+00,  4.4470e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.2258e+00, -9.7833e+00, -8.0045e+00, -4.4470e+00],\n",
      "          [-8.0045e+00, -1.5120e+01, -1.1562e+01, -6.2258e+00],\n",
      "          [-8.8939e-01, -4.4470e+00, -3.5576e+00, -3.5576e+00],\n",
      "          [ 5.3364e+00, -1.7788e+00, -3.5576e+00, -2.6682e+00]],\n",
      "\n",
      "         [[ 8.0045e+00,  1.0673e+01,  1.2452e+01,  4.4470e+00],\n",
      "          [ 5.3364e+00,  1.4230e+01,  1.6898e+01,  5.3364e+00],\n",
      "          [ 3.5576e+00,  1.1562e+01,  1.6009e+01,  6.2258e+00],\n",
      "          [-5.3364e+00,  4.4470e+00,  9.7833e+00,  2.6682e+00]],\n",
      "\n",
      "         [[ 8.0045e+00,  8.8939e+00,  7.1152e+00,  1.7788e+00],\n",
      "          [ 8.0045e+00,  8.8939e+00,  8.0045e+00,  1.7788e+00],\n",
      "          [ 8.4819e-08,  1.7788e+00,  8.8939e-01,  8.8939e-01],\n",
      "          [-8.8939e-01, -8.8939e-01, -8.8939e-01,  5.6546e-08]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3364e+00,  9.7833e+00,  1.0673e+01,  1.0673e+01],\n",
      "          [-2.6682e+00,  0.0000e+00,  6.2258e+00,  1.0673e+01],\n",
      "          [-3.5576e+00, -8.8939e-01,  6.2258e+00,  8.8939e+00],\n",
      "          [-3.5576e+00, -8.8939e-01,  6.2258e+00,  8.8939e+00]],\n",
      "\n",
      "         [[ 4.4470e+00,  7.1152e+00,  5.3364e+00,  6.2258e+00],\n",
      "          [ 6.7855e-07,  7.1152e+00,  9.7833e+00,  7.1152e+00],\n",
      "          [ 8.8939e-01,  2.6682e+00,  7.1152e+00,  8.0045e+00],\n",
      "          [-8.8939e-01,  1.7788e+00,  1.7788e+00, -1.7788e+00]],\n",
      "\n",
      "         [[ 6.2258e+00,  8.0045e+00,  9.7833e+00,  8.8939e+00],\n",
      "          [-3.5576e+00,  2.6682e+00,  7.1152e+00,  8.8939e+00],\n",
      "          [-2.6682e+00,  3.5576e+00,  5.3364e+00,  7.1152e+00],\n",
      "          [-3.5576e+00,  3.5576e+00,  6.2258e+00,  6.2258e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.1152e+00,  8.0045e+00,  2.6682e+00, -1.7788e+00],\n",
      "          [ 5.3364e+00, -8.8939e-01, -4.4470e+00, -8.8939e+00],\n",
      "          [ 6.2258e+00,  4.4470e+00,  1.9791e-07, -4.4470e+00],\n",
      "          [ 5.3364e+00, -8.8939e-01, -2.6682e+00, -2.6682e+00]],\n",
      "\n",
      "         [[ 8.0045e+00,  1.0673e+01,  1.2452e+01,  4.4470e+00],\n",
      "          [ 3.5576e+00,  1.1562e+01,  1.4230e+01,  4.4470e+00],\n",
      "          [ 2.6682e+00,  8.8939e+00,  1.4230e+01,  6.2258e+00],\n",
      "          [ 8.8939e-01,  8.8939e+00,  1.1562e+01,  2.6682e+00]],\n",
      "\n",
      "         [[-2.8273e-08,  8.8939e-01,  0.0000e+00,  8.8939e-01],\n",
      "          [-8.8939e-01, -8.8939e-01,  1.7788e+00,  6.2258e+00],\n",
      "          [-8.8939e-01, -2.8273e-08, -2.8273e-08,  8.8939e-01],\n",
      "          [-8.8939e-01, -8.8939e-01,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.3364e+00,  1.1562e+01,  1.1562e+01,  1.1562e+01],\n",
      "          [ 6.2258e+00,  8.8939e+00,  8.0045e+00,  9.7833e+00],\n",
      "          [-1.7788e+00,  4.4470e+00,  9.7833e+00,  8.8939e+00],\n",
      "          [-1.7788e+00,  5.3364e+00,  8.8939e+00,  8.8939e+00]],\n",
      "\n",
      "         [[-4.4470e+00,  8.8939e-01,  7.1152e+00,  3.3928e-07],\n",
      "          [ 1.7788e+00,  3.5576e+00,  7.1152e+00,  6.2258e+00],\n",
      "          [-8.8939e-01, -8.8939e-01,  7.1152e+00,  8.0045e+00],\n",
      "          [-5.6546e-08,  2.6682e+00,  2.6682e+00, -1.7788e+00]],\n",
      "\n",
      "         [[-6.2258e+00, -1.7788e+00,  6.2258e+00,  8.8939e+00],\n",
      "          [-4.4470e+00,  3.5576e+00,  8.8939e+00,  8.8939e+00],\n",
      "          [-8.8939e+00, -2.6682e+00,  4.4470e+00,  7.1152e+00],\n",
      "          [-3.5576e+00,  2.6682e+00,  5.3364e+00,  6.2258e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0045e+00,  3.5576e+00, -6.2258e+00, -9.7833e+00],\n",
      "          [-1.7788e+00, -9.7833e+00, -1.2452e+01, -1.2452e+01],\n",
      "          [ 6.2258e+00, -1.7788e+00, -4.4470e+00, -4.4470e+00],\n",
      "          [ 7.1152e+00,  4.4470e+00,  0.0000e+00, -2.6682e+00]],\n",
      "\n",
      "         [[-3.5576e+00,  3.5576e+00,  1.0673e+01,  3.5576e+00],\n",
      "          [ 1.7788e+00,  8.8939e+00,  1.3341e+01,  6.2258e+00],\n",
      "          [-2.6682e+00,  7.1152e+00,  1.3341e+01,  7.1152e+00],\n",
      "          [ 8.8939e-01,  7.1152e+00,  1.0673e+01,  2.6682e+00]],\n",
      "\n",
      "         [[ 5.6546e-08,  2.6682e+00,  8.0045e+00,  8.0045e+00],\n",
      "          [ 8.0045e+00,  8.8939e+00,  8.8939e+00,  8.8939e+00],\n",
      "          [ 5.6546e-08,  1.7788e+00,  1.7788e+00,  1.7788e+00],\n",
      "          [-8.8939e-01, -1.1309e-07, -8.8939e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.8939e-01,  6.2258e+00,  1.0673e+01,  1.1562e+01],\n",
      "          [ 4.5237e-07,  5.3364e+00,  8.8939e+00,  9.7833e+00],\n",
      "          [-4.4470e+00, -8.8939e-01,  5.3364e+00,  8.8939e+00],\n",
      "          [-3.5576e+00, -8.8939e-01,  4.4470e+00,  8.8939e+00]],\n",
      "\n",
      "         [[-3.5576e+00,  3.5576e+00,  6.2258e+00,  6.2258e+00],\n",
      "          [ 8.8939e-01,  2.6682e+00,  8.0045e+00,  7.1152e+00],\n",
      "          [-8.8939e-01,  2.8273e-08,  8.8939e+00,  1.7788e+00],\n",
      "          [-8.8939e-01,  0.0000e+00,  1.7788e+00, -2.6682e+00]],\n",
      "\n",
      "         [[-8.8939e-01,  4.4470e+00,  8.0045e+00,  8.8939e+00],\n",
      "          [-4.4470e+00,  3.5576e+00,  8.0045e+00,  8.0045e+00],\n",
      "          [-1.0673e+01, -3.5576e+00,  3.5576e+00,  7.1152e+00],\n",
      "          [-8.8939e+00, -3.5576e+00,  4.4470e+00,  6.2258e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.0045e+00,  4.4470e+00, -4.4470e+00, -9.7833e+00],\n",
      "          [ 5.3364e+00, -2.6682e+00, -9.7833e+00, -1.2452e+01],\n",
      "          [ 7.1152e+00,  3.5576e+00, -1.7788e+00, -4.4470e+00],\n",
      "          [ 5.3364e+00, -8.8939e-01, -2.6682e+00, -2.6682e+00]],\n",
      "\n",
      "         [[ 2.6682e+00,  8.0045e+00,  1.2452e+01,  4.4470e+00],\n",
      "          [ 1.7788e+00,  9.7833e+00,  1.3341e+01,  7.1152e+00],\n",
      "          [-4.4470e+00,  4.4470e+00,  1.3341e+01,  6.2258e+00],\n",
      "          [-5.3364e+00,  3.5576e+00,  8.8939e+00,  2.6682e+00]],\n",
      "\n",
      "         [[-8.8939e-01,  2.6682e+00,  8.0045e+00,  8.0045e+00],\n",
      "          [-8.8939e-01,  2.6682e+00,  8.8939e+00,  8.8939e+00],\n",
      "          [-8.8939e-01, -5.6546e-08, -5.6546e-08,  1.7788e+00],\n",
      "          [-8.8939e-01, -8.8939e-01,  0.0000e+00,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-8.8939e-01,  6.2258e+00,  1.0673e+01,  1.0673e+01],\n",
      "          [-3.5576e+00, -1.7788e+00,  2.6682e+00,  8.8939e+00],\n",
      "          [-3.5576e+00, -1.7788e+00,  4.4470e+00,  9.7833e+00],\n",
      "          [-4.4470e+00, -2.6682e+00,  3.5576e+00,  7.1152e+00]],\n",
      "\n",
      "         [[ 8.8939e-01,  4.4470e+00,  7.1152e+00,  3.3928e-07],\n",
      "          [ 7.1152e+00,  1.1562e+01,  1.2452e+01,  8.0045e+00],\n",
      "          [ 1.7788e+00,  1.7788e+00,  8.8939e-01, -1.7788e+00],\n",
      "          [-8.8939e-01,  0.0000e+00,  1.7788e+00, -1.7788e+00]],\n",
      "\n",
      "         [[-7.1152e+00,  9.0474e-07,  7.1152e+00,  7.1152e+00],\n",
      "          [-1.0673e+01, -6.2258e+00,  3.5576e+00,  5.3364e+00],\n",
      "          [-9.7833e+00, -8.8939e+00, -3.5576e+00,  3.5576e+00],\n",
      "          [-8.8939e+00, -3.5576e+00,  2.6682e+00,  6.2258e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.1152e+00,  7.1152e+00,  3.3928e-07, -7.1152e+00],\n",
      "          [ 8.0045e+00,  8.0045e+00,  6.2258e+00, -1.7788e+00],\n",
      "          [ 7.1152e+00,  6.2258e+00,  3.5576e+00, -4.4470e+00],\n",
      "          [ 7.1152e+00,  4.4470e+00, -5.6546e-08, -4.4470e+00]],\n",
      "\n",
      "         [[-4.4470e+00,  4.4470e+00,  8.8939e+00,  2.6682e+00],\n",
      "          [-3.5576e+00,  5.3364e+00,  1.2452e+01,  5.3364e+00],\n",
      "          [-4.4470e+00, -2.6682e+00,  4.4470e+00, -4.5237e-07],\n",
      "          [-5.3364e+00,  2.6682e+00,  7.1152e+00,  1.7788e+00]],\n",
      "\n",
      "         [[-8.8939e-01,  2.6682e+00,  8.8939e+00,  8.8939e+00],\n",
      "          [-8.8939e-01,  0.0000e+00,  2.6682e+00,  8.8939e+00],\n",
      "          [-8.8939e-01,  0.0000e+00,  2.6682e+00,  8.0045e+00],\n",
      "          [-8.8939e-01,  8.8939e-01,  8.0045e+00,  8.0045e+00]]]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 8, out_channels=8, kernel_size = 3, padding=1, bias=False)\n",
    "conv_int.to(device)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "output_int = conv_int(x_int)\n",
    "output_recovered = output_int*x_delta*w_delta\n",
    "print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 8, 4, 4])\n",
      "torch.Size([128, 8, 4, 4])\n",
      "tensor(5.6099e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output_recovered.shape)\n",
    "print(save_output.outputs[8][0].shape)\n",
    "relu_output_recovered = model.features[27](output_recovered) #RElU\n",
    "difference = abs(save_output.outputs[9][0] - relu_output_recovered )  ##Difference between prehooked input of next layer\n",
    "print(difference.mean()) ## It should be small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-whole",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
